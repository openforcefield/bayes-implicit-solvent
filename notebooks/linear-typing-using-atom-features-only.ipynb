{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:02:09.620806Z",
     "start_time": "2019-03-07T14:02:09.617187Z"
    }
   },
   "outputs": [],
   "source": [
    "from bayes_implicit_solvent.continuous_parameter_experiments.gradient_free import mols as all_mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:02:09.843539Z",
     "start_time": "2019-03-07T14:02:09.837209Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:02:10.046067Z",
     "start_time": "2019-03-07T14:02:10.040676Z"
    }
   },
   "outputs": [],
   "source": [
    "from bayes_implicit_solvent.constants import beta\n",
    "def unreduce(value):\n",
    "    \"\"\"Input value is in units of kB T, turn it into units of kilocalorie_per_mole\"\"\"\n",
    "    return value / (beta * unit.kilocalorie_per_mole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:02:13.509435Z",
     "start_time": "2019-03-07T14:02:10.529988Z"
    }
   },
   "outputs": [],
   "source": [
    "# at this stage, let's eliminate any molecule that has an experimental value outside of [-15, +5]\n",
    "\n",
    "mols = []\n",
    "    \n",
    "from bayes_implicit_solvent.utils import get_charges\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from simtk import unit\n",
    "elements = []\n",
    "charges = []\n",
    "distance_matrices = []\n",
    "expt_means = []\n",
    "expt_uncs = []\n",
    "vacuum_trajs = []\n",
    "for mol in all_mols:\n",
    "    \n",
    "    expt_mean = unreduce(mol.experimental_value)\n",
    "    expt_unc = unreduce(mol.experimental_uncertainty)\n",
    "    \n",
    "    if (expt_mean > -15) and (expt_mean < 5):\n",
    "        \n",
    "        mols.append(mol)\n",
    "        expt_means.append(expt_mean)\n",
    "        expt_uncs.append(expt_unc)\n",
    "\n",
    "        elements.append(np.array([a.element.atomic_number for a in mol.top.atoms()]))\n",
    "        charges.append(get_charges(mol.sys))\n",
    "        distance_matrices.append([squareform(pdist(snapshot / unit.nanometer)) for snapshot in mol.vacuum_traj])\n",
    "expt_means = np.array(expt_means)\n",
    "expt_uncs = np.array(expt_uncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:55.630809Z",
     "start_time": "2019-03-07T14:04:55.619504Z"
    }
   },
   "outputs": [],
   "source": [
    "# THE CODE IN THIS CELL IS ADAPTED FROM https://github.com/HIPS/neural-fingerprint\n",
    "# ACCOMPANYING \"Convolutional Networks on Graphs for Learning Molecular Fingerprints\"\n",
    "# by David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael Gómez-Bombarelli, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P. Adams.\n",
    "\n",
    "import autograd.numpy as np\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def atom_features(atom):\n",
    "    \"\"\"Use some OpenEye features instead\"\"\"\n",
    "    return np.array(one_of_k_encoding_unk(atom.GetAtomicNum(),\n",
    "                                      [1, 35, 6, 7, 8, 9, 15, 16, 17, 53, -1]) +\n",
    "                    one_of_k_encoding(atom.GetDegree(), [1, 2, 3, 4]) +\n",
    "                    one_of_k_encoding(atom.GetValence(), [1, 2, 3, 4, 5, 6]) +\n",
    "                    one_of_k_encoding(atom.GetHvyValence(), [0, 1, 2, 3, 4, 5, 6]) +\n",
    "                    one_of_k_encoding(atom.GetHvyDegree(), [0, 1, 2, 3, 4]) +\n",
    "                    one_of_k_encoding(atom.GetTotalHCount(), [0, 1, 2, 3, 4]) +\n",
    "                    [atom.IsAromatic(), atom.IsHalogen(), atom.IsPolarHydrogen(), atom.IsMetal(), atom.IsInRing()] # binary features\n",
    "                   )\n",
    "def num_atom_features():\n",
    "    atoms = list(mols[0].mol.GetAtoms())\n",
    "    return len(atom_features(atoms[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.191291Z",
     "start_time": "2019-03-07T14:04:56.139496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_features(mol):\n",
    "    return np.vstack([atom_features(a) for a in mol.GetAtoms()])\n",
    "\n",
    "computed_features = list(map(compute_features, [mol.mol for mol in mols]))\n",
    "len(computed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.202250Z",
     "start_time": "2019-03-07T14:04:59.195803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = num_atom_features()\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.209066Z",
     "start_time": "2019-03-07T14:04:59.205463Z"
    }
   },
   "outputs": [],
   "source": [
    "from autograd.scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.220054Z",
     "start_time": "2019-03-07T14:04:59.213941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distance_matrices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.233079Z",
     "start_time": "2019-03-07T14:04:59.225066Z"
    }
   },
   "outputs": [],
   "source": [
    "N_atoms = np.array(list(map(len, charges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.242609Z",
     "start_time": "2019-03-07T14:04:59.236571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.250774Z",
     "start_time": "2019-03-07T14:04:59.245416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = N\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.260494Z",
     "start_time": "2019-03-07T14:04:59.253720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15, 0.8 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_radius = 0.15\n",
    "default_scale = 0.8\n",
    "baseline_bias = np.array([default_radius, default_scale])\n",
    "baseline_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.268678Z",
     "start_time": "2019-03-07T14:04:59.263647Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    \"Rectified linear activation function.\"\n",
    "    return X * (X > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.287793Z",
     "start_time": "2019-03-07T14:04:59.272108Z"
    }
   },
   "outputs": [],
   "source": [
    "import autograd.numpy.random as npr\n",
    "\n",
    "class NeuralNet():\n",
    "\n",
    "    def __init__(self, layer_sizes, scale=0.01):\n",
    "        assert(layer_sizes[-1] == 2)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.scale = scale\n",
    "        self.params = self.init_random_params(scale, layer_sizes)\n",
    "\n",
    "    def init_random_params(self, scale, layer_sizes, rs=npr.RandomState(0)):\n",
    "        return [(scale * rs.randn(m, n),  # weight matrix\n",
    "                 scale * rs.randn(n))  # bias vector\n",
    "                for m, n in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "\n",
    "    def neural_net_predict(self, params, inputs):\n",
    "        for W, b in params:\n",
    "            outputs = np.dot(inputs, W) + b\n",
    "            inputs = relu(outputs)\n",
    "        return outputs + baseline_bias\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.neural_net_predict(self.params, inputs)\n",
    "    \n",
    "npr.seed(0)\n",
    "layer_sizes = [n_features, 2]\n",
    "neural_net = NeuralNet(layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.297221Z",
     "start_time": "2019-03-07T14:04:59.292063Z"
    }
   },
   "outputs": [],
   "source": [
    "params = neural_net.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:59.585464Z",
     "start_time": "2019-03-07T14:04:59.578338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20804834, 0.79478895],\n",
       "       [0.17475065, 0.79627458],\n",
       "       [0.16188043, 0.79518197],\n",
       "       [0.19613242, 0.82061456],\n",
       "       [0.13902075, 0.77676231],\n",
       "       [0.12769472, 0.78161642],\n",
       "       [0.14320772, 0.79528638],\n",
       "       [0.14320772, 0.79528638],\n",
       "       [0.13902075, 0.77676231],\n",
       "       [0.12769472, 0.78161642],\n",
       "       [0.14320772, 0.79528638],\n",
       "       [0.14320772, 0.79528638],\n",
       "       [0.16188043, 0.79518197],\n",
       "       [0.16188043, 0.79518197],\n",
       "       [0.16188043, 0.79518197],\n",
       "       [0.16188043, 0.79518197],\n",
       "       [0.16188043, 0.79518197]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net(computed_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:01.148501Z",
     "start_time": "2019-03-07T14:05:01.145281Z"
    }
   },
   "outputs": [],
   "source": [
    "from bayes_implicit_solvent.gb_models.numpy_gb_models import compute_OBC_energy_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:02.354683Z",
     "start_time": "2019-03-07T14:05:02.338934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.20804834, 0.17475065, 0.16188043, 0.19613242, 0.13902075,\n",
       "        0.12769472, 0.14320772, 0.14320772, 0.13902075, 0.12769472,\n",
       "        0.14320772, 0.14320772, 0.16188043, 0.16188043, 0.16188043,\n",
       "        0.16188043, 0.16188043]),\n",
       " array([0.79478895, 0.79627458, 0.79518197, 0.82061456, 0.77676231,\n",
       "        0.78161642, 0.79528638, 0.79528638, 0.77676231, 0.78161642,\n",
       "        0.79528638, 0.79528638, 0.79518197, 0.79518197, 0.79518197,\n",
       "        0.79518197, 0.79518197]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radii, scales = neural_net.neural_net_predict(params, computed_features[0]).T\n",
    "radii, scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:02.840114Z",
     "start_time": "2019-03-07T14:05:02.834812Z"
    }
   },
   "outputs": [],
   "source": [
    "npr.seed(0)\n",
    "all_inds = np.arange(len(mols))\n",
    "np.random.shuffle(all_inds)\n",
    "train_inds = all_inds[::2]\n",
    "test_inds = all_inds[1::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:03.519290Z",
     "start_time": "2019-03-07T14:05:03.510123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1382    ,  0.1522    ,  0.1023    ,  0.1233    , -0.3511    ,\n",
       "        0.37990001, -0.1655    , -0.1655    , -0.37040001,  0.3845    ,\n",
       "       -0.1723    , -0.1723    ,  0.0681    ,  0.0681    ,  0.0681    ,\n",
       "        0.0944    ,  0.0944    ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:04.398757Z",
     "start_time": "2019-03-07T14:05:04.393183Z"
    }
   },
   "outputs": [],
   "source": [
    "from autograd.scipy.misc import logsumexp\n",
    "from simtk import unit\n",
    "from bayes_implicit_solvent.constants import kB, temperature\n",
    "\n",
    "kj_mol_to_kT = 1.0 * unit.kilojoule_per_mole / (kB * temperature)\n",
    "\n",
    "def one_sided_exp(w_F):\n",
    "    DeltaF = - (logsumexp(- w_F) - np.log(len(w_F)))\n",
    "    return DeltaF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:05.199878Z",
     "start_time": "2019-03-07T14:05:05.139647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_types = np.array(sorted(list(set([tuple(f) for f in np.vstack(computed_features)]))))\n",
    "len(all_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:06.766976Z",
     "start_time": "2019-03-07T14:05:06.761003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "        True, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:07.357228Z",
     "start_time": "2019-03-07T14:05:07.347414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_index = dict(zip([tuple(t) for t in all_types], range(len(all_types))))\n",
    "type_index[tuple(computed_features[0][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:08.638883Z",
     "start_time": "2019-03-07T14:05:08.536543Z"
    }
   },
   "outputs": [],
   "source": [
    "type_indices = []\n",
    "for i in range(len(computed_features)):\n",
    "    type_indices.append(np.array([type_index[tuple(f)] for f in computed_features[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:58.741558Z",
     "start_time": "2019-03-07T14:05:58.733570Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_predictions(params, inds=train_inds, batch_size=5, randomized=True):\n",
    "    all_radii, all_scales = neural_net.neural_net_predict(params, all_types).T\n",
    "    \n",
    "    \n",
    "    predictions = []\n",
    "    for i in inds:\n",
    "        radii, scales= all_radii[type_indices[i]], all_scales[type_indices[i]]\n",
    "        #radii, scales, log_taus = neural_net.neural_net_predict(params, computed_features[i]).T\n",
    "        #taus = np.exp(log_taus)\n",
    "        \n",
    "        if randomized:\n",
    "            dmat_inds = np.random.randint(0, len(distance_matrices[i]), batch_size)\n",
    "        else:\n",
    "            dmat_inds = np.arange(min(batch_size, len(distance_matrices[i])))\n",
    "        W_F = np.array([compute_OBC_energy_vectorized(distance_matrices[i][j], radii, scales, charges=charges[i]) for j in dmat_inds])\n",
    "        \n",
    "        w_F = W_F * kj_mol_to_kT\n",
    "        pred_free_energy = unreduce(one_sided_exp(w_F))\n",
    "        predictions.append(pred_free_energy)\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:05:59.837169Z",
     "start_time": "2019-03-07T14:05:59.237709Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = make_predictions(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:06:01.045594Z",
     "start_time": "2019-03-07T14:06:01.038560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10763877806275707"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_prior(params):\n",
    "    return - sum([np.linalg.norm(W) + np.linalg.norm(b) for (W,b) in params])\n",
    "log_prior(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:06:01.741847Z",
     "start_time": "2019-03-07T14:06:01.728916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.950e+00, -4.590e+00, -7.400e-01, -9.840e+00, -2.400e+00,\n",
       "       -6.480e+00,  1.070e+00, -3.430e+00,  1.830e+00, -4.290e+00,\n",
       "       -3.200e+00, -2.220e+00, -2.370e+00, -7.000e-01, -1.960e+00,\n",
       "       -2.490e+00, -4.800e-01, -4.220e+00, -4.510e+00, -2.860e+00,\n",
       "       -6.190e+00, -9.630e+00, -1.620e+00, -2.490e+00, -3.800e+00,\n",
       "       -2.550e+00, -3.880e+00, -1.460e+00, -9.000e-01, -7.620e+00,\n",
       "       -1.343e+01, -1.114e+01, -6.400e-01, -1.920e+00,  2.500e-01,\n",
       "       -3.750e+00, -2.210e+00,  2.670e+00, -4.710e+00, -3.840e+00,\n",
       "        3.430e+00, -3.780e+00, -6.160e+00, -3.820e+00, -4.590e+00,\n",
       "       -3.560e+00, -2.810e+00, -5.000e-01, -4.330e+00,  1.160e+00,\n",
       "       -3.280e+00, -7.800e-01, -3.680e+00, -2.530e+00, -1.101e+01,\n",
       "       -2.640e+00, -7.980e+00, -7.030e+00, -1.100e+00, -6.120e+00,\n",
       "       -4.850e+00, -1.160e+00, -2.490e+00, -7.500e+00, -2.480e+00,\n",
       "       -4.230e+00, -3.810e+00, -2.340e+00, -2.690e+00, -5.220e+00,\n",
       "       -2.780e+00,  2.880e+00, -3.640e+00, -3.520e+00, -9.820e+00,\n",
       "        1.200e+00, -2.560e+00, -3.130e+00, -6.620e+00,  1.660e+00,\n",
       "       -1.960e+00, -6.800e-01, -2.870e+00,  3.120e+00, -2.380e+00,\n",
       "       -4.870e+00, -4.420e+00,  8.400e-01,  2.340e+00, -2.630e+00,\n",
       "       -4.690e+00, -9.200e+00, -6.230e+00, -4.210e+00, -3.370e+00,\n",
       "        2.900e-01, -3.670e+00, -1.000e+01, -3.640e+00, -5.600e-01,\n",
       "       -4.590e+00, -1.000e-01, -3.510e+00, -7.800e-01, -4.020e+00,\n",
       "        5.600e-01, -1.610e+00, -9.940e+00,  1.600e-01,  1.400e-01,\n",
       "       -1.500e+00, -5.910e+00, -1.200e+00, -5.310e+00, -1.022e+01,\n",
       "        1.920e+00, -4.020e+00, -5.660e+00, -4.290e+00, -6.010e+00,\n",
       "       -9.650e+00, -4.000e-01, -5.530e+00, -2.940e+00, -1.240e+00,\n",
       "       -9.730e+00, -5.730e+00, -5.210e+00, -6.340e+00,  2.110e+00,\n",
       "       -2.150e+00, -2.460e+00, -2.330e+00, -2.160e+00, -7.780e+00,\n",
       "       -9.010e+00, -1.078e+01, -8.210e+00, -6.130e+00, -3.500e+00,\n",
       "       -1.880e+00, -4.000e-01, -1.340e+00, -1.600e-01, -3.150e+00,\n",
       "       -4.860e+00, -4.040e+00, -1.290e+00, -3.520e+00, -4.000e-02,\n",
       "       -1.120e+00, -4.500e+00, -6.550e+00, -9.760e+00, -3.340e+00,\n",
       "       -4.840e+00,  2.880e+00, -1.910e+00, -2.880e+00, -4.270e+00,\n",
       "       -2.320e+00, -3.000e-01, -1.590e+00, -1.400e+00, -1.000e-01,\n",
       "       -4.130e+00, -4.500e-01, -3.880e+00, -8.720e+00, -7.000e+00,\n",
       "       -3.730e+00, -2.930e+00, -5.940e+00, -5.110e+00, -5.330e+00,\n",
       "       -1.100e-01, -1.274e+01, -9.130e+00, -2.920e+00, -5.260e+00,\n",
       "       -2.260e+00, -1.360e+00, -1.240e+00,  1.310e+00, -5.900e+00,\n",
       "       -3.040e+00, -5.490e+00, -6.160e+00, -5.660e+00, -9.500e-01,\n",
       "       -4.700e+00,  6.700e-01, -9.400e+00, -4.620e+00, -4.200e+00,\n",
       "       -4.840e+00, -6.720e+00, -9.000e-01, -7.400e-01, -5.290e+00,\n",
       "       -2.230e+00, -1.380e+00, -5.300e-01, -2.730e+00, -6.500e+00,\n",
       "       -3.110e+00, -4.090e+00, -3.300e-01, -4.090e+00, -2.670e+00,\n",
       "       -4.800e+00, -6.690e+00, -8.000e-01, -4.390e+00, -4.390e+00,\n",
       "       -1.600e-01, -2.010e+00,  1.000e-01, -5.990e+00, -5.490e+00,\n",
       "       -4.100e+00,  2.930e+00, -1.120e+00, -4.440e+00, -5.300e-01,\n",
       "       -4.550e+00,  2.830e+00, -7.770e+00, -8.680e+00, -3.300e+00,\n",
       "       -6.500e+00,  0.000e+00, -3.610e+00, -5.900e+00, -8.000e-01,\n",
       "        1.580e+00, -5.900e-01, -3.950e+00, -3.440e+00, -3.170e+00,\n",
       "       -9.800e-01, -6.690e+00, -6.250e+00, -1.017e+01, -1.140e+00,\n",
       "       -3.650e+00, -6.200e+00, -9.860e+00, -1.264e+01, -7.580e+00,\n",
       "       -3.200e+00, -4.420e+00,  2.000e+00,  6.000e-01,  2.480e+00,\n",
       "       -2.490e+00,  2.300e+00, -3.520e+00,  3.160e+00, -5.040e+00,\n",
       "       -5.820e+00, -4.820e+00,  2.560e+00,  2.060e+00, -4.580e+00,\n",
       "       -3.050e+00, -1.240e+00, -8.500e-01, -6.100e+00, -4.520e+00,\n",
       "        1.800e-01, -3.410e+00, -6.620e+00, -4.430e+00, -2.440e+00,\n",
       "       -5.100e+00, -4.470e+00, -5.560e+00, -1.790e+00, -9.620e+00,\n",
       "       -2.680e+00,  2.890e+00, -3.540e+00,  8.000e-02, -2.890e+00,\n",
       "       -1.210e+00, -2.920e+00, -4.720e+00,  1.590e+00, -3.100e+00,\n",
       "       -1.640e+00, -5.460e+00, -7.810e+00, -2.280e+00, -9.000e-01,\n",
       "       -3.350e+00, -9.280e+00, -2.300e+00,  1.790e+00, -5.490e+00,\n",
       "       -2.550e+00,  1.280e+00, -2.290e+00, -2.070e+00, -2.500e-01,\n",
       "       -1.027e+01, -8.610e+00, -4.680e+00,  2.550e+00,  2.510e+00,\n",
       "       -9.610e+00, -3.470e+00, -2.560e+00,  3.130e+00, -1.170e+00,\n",
       "       -5.330e+00,  1.000e-01, -1.340e+00, -6.000e+00, -6.790e+00,\n",
       "       -4.630e+00, -3.220e+00,  2.930e+00, -6.780e+00,  5.200e-01,\n",
       "       -5.800e+00, -7.000e+00,  1.680e+00, -5.880e+00,  0.000e+00,\n",
       "       -3.880e+00, -1.390e+00, -2.450e+00, -1.008e+01, -3.640e+00,\n",
       "       -8.260e+00, -1.450e+00, -4.370e+00, -5.300e-01, -8.700e+00,\n",
       "       -3.430e+00, -3.000e-02, -1.950e+00, -6.460e+00, -6.300e-01,\n",
       "       -4.400e+00, -7.280e+00, -4.570e+00, -6.320e+00, -1.210e+00,\n",
       "       -6.020e+00, -7.650e+00, -8.300e-01, -5.000e+00, -2.210e+00,\n",
       "       -4.740e+00, -3.220e+00, -6.210e+00, -1.064e+01, -3.710e+00,\n",
       "       -4.230e+00, -1.280e+00, -4.730e+00, -2.830e+00,  2.000e+00,\n",
       "        5.000e-01, -5.100e+00, -4.400e+00, -4.050e+00, -3.250e+00,\n",
       "       -7.660e+00, -2.820e+00, -3.130e+00, -8.900e-01, -1.010e+00,\n",
       "       -9.300e+00, -6.400e+00, -4.820e+00, -7.170e+00,  1.380e+00,\n",
       "       -5.910e+00, -7.630e+00, -2.220e+00, -2.470e+00, -1.195e+01,\n",
       "       -2.020e+00, -6.960e+00, -3.920e+00, -2.450e+00, -2.500e-01,\n",
       "       -4.290e+00, -4.400e+00, -5.720e+00, -7.070e+00, -3.880e+00,\n",
       "        7.100e-01, -4.720e+00, -4.400e-01, -2.100e+00, -2.280e+00,\n",
       "       -4.120e+00, -4.240e+00,  2.510e+00, -8.400e-01, -5.500e-01,\n",
       "       -4.690e+00, -7.290e+00, -5.450e+00, -8.180e+00, -1.140e+00,\n",
       "       -3.880e+00, -6.250e+00,  1.070e+00, -6.680e+00, -9.450e+00,\n",
       "       -4.910e+00,  1.830e+00, -2.640e+00, -6.270e+00, -9.400e+00,\n",
       "       -5.850e+00, -4.390e+00, -5.740e+00, -2.090e+00, -4.420e+00,\n",
       "       -4.610e+00, -8.150e+00, -1.100e-01, -4.910e+00, -7.370e+00,\n",
       "       -7.100e+00,  6.800e-01,  5.600e-01, -2.500e-01, -3.950e+00,\n",
       "        2.380e+00, -9.290e+00, -7.430e+00, -2.780e+00, -4.870e+00,\n",
       "       -2.200e-01, -2.740e+00,  2.710e+00, -1.660e+00, -8.830e+00,\n",
       "        1.680e+00, -4.450e+00, -7.470e+00, -4.590e+00, -7.190e+00,\n",
       "       -4.600e-01, -3.240e+00, -1.100e+00, -2.490e+00, -1.310e+00,\n",
       "       -3.120e+00, -4.800e-01, -2.930e+00, -1.100e+01, -6.090e+00,\n",
       "       -4.060e+00, -4.090e+00, -4.970e+00, -3.180e+00,  2.520e+00,\n",
       "       -2.640e+00,  1.470e+00, -9.710e+00, -1.230e+00, -7.290e+00,\n",
       "       -3.640e+00, -5.040e+00, -8.600e-01, -4.700e+00, -5.570e+00,\n",
       "        1.770e+00,  2.930e+00, -3.790e+00, -6.500e+00, -4.930e+00,\n",
       "       -9.510e+00, -4.380e+00,  2.560e+00,  1.580e+00, -6.790e+00,\n",
       "       -5.710e+00, -9.440e+00, -9.370e+00, -6.880e+00, -1.270e+00,\n",
       "        4.000e-01, -2.110e+00, -3.900e+00, -5.260e+00, -5.180e+00,\n",
       "        2.510e+00, -6.920e+00,  2.130e+00, -4.350e+00, -4.420e+00,\n",
       "       -1.740e+00, -6.750e+00, -5.510e+00, -4.780e+00, -4.500e+00,\n",
       "       -1.830e+00,  1.700e+00, -2.700e+00, -3.450e+00, -1.990e+00,\n",
       "       -6.350e+00, -3.300e+00, -9.800e+00,  2.300e+00, -8.000e-01,\n",
       "       -4.100e+00, -2.360e+00, -2.510e+00, -3.650e+00, -7.400e+00,\n",
       "       -4.610e+00, -1.185e+01,  7.500e-01, -4.530e+00, -6.440e+00,\n",
       "       -3.450e+00, -1.080e+00, -3.840e+00, -4.010e+00, -1.820e+00,\n",
       "        2.700e-01, -1.460e+00, -2.820e+00, -2.750e+00, -5.700e-01,\n",
       "       -6.400e+00, -4.770e+00, -1.430e+00, -2.130e+00, -9.300e+00,\n",
       "        1.010e+00,  3.400e-01, -5.220e+00, -4.150e+00, -4.000e+00,\n",
       "       -6.740e+00, -7.780e+00, -6.600e+00, -1.120e+00,  1.000e-02,\n",
       "       -1.003e+01,  2.100e+00, -6.130e+00, -8.410e+00, -7.480e+00,\n",
       "       -4.550e+00,  2.510e+00, -8.110e+00,  2.970e+00, -4.070e+00,\n",
       "       -1.153e+01, -2.300e-01, -1.690e+00, -7.900e-01, -2.400e+00,\n",
       "       -9.900e-01, -3.040e+00, -5.060e+00, -3.090e+00, -3.580e+00,\n",
       "       -7.670e+00, -2.330e+00, -9.410e+00, -4.160e+00, -3.150e+00,\n",
       "       -4.310e+00, -6.620e+00, -5.730e+00, -3.480e+00,  8.000e-02,\n",
       "       -9.530e+00, -8.300e-01, -2.490e+00, -2.040e+00, -4.400e-01,\n",
       "       -5.210e+00, -3.710e+00, -1.930e+00, -5.480e+00, -2.440e+00,\n",
       "       -9.520e+00, -8.840e+00,  9.300e-01, -1.400e-01, -9.340e+00,\n",
       "        6.000e-02, -5.480e+00, -9.610e+00, -5.030e+00,  1.310e+00,\n",
       "       -1.421e+01, -3.930e+00, -1.460e+00, -2.130e+00, -2.790e+00,\n",
       "       -5.730e+00, -3.030e+00, -3.280e+00, -2.980e+00, -7.700e-01,\n",
       "       -2.400e+00,  1.090e+00, -8.840e+00, -1.660e+00, -2.780e+00,\n",
       "       -3.920e+00, -4.580e+00, -1.021e+01, -9.310e+00, -5.230e+00,\n",
       "       -1.900e-01, -9.000e-01, -8.420e+00,  1.230e+00, -9.900e-01,\n",
       "       -8.200e-01, -4.780e+00, -1.890e+00, -3.240e+00,  1.320e+00,\n",
       "        2.900e-01])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:06:02.400644Z",
     "start_time": "2019-03-07T14:06:02.390720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.50194871e+00,  6.37843862e-01,  1.89624991e+00, -1.21373107e+00,\n",
       "        1.34126144e+00, -1.39692222e+01, -1.51423227e+00, -1.63324279e+00,\n",
       "       -2.11615091e+00, -3.32313807e+00, -4.81679744e+00, -2.97252849e-01,\n",
       "        8.88266110e-01, -2.42793217e+00, -6.97217360e+00, -1.70258106e+00,\n",
       "       -4.65185033e-01, -1.43886820e+00, -6.43169764e+00, -7.15907422e+00,\n",
       "        7.98415846e-01, -7.46285990e+00, -4.12695678e+00, -1.47577784e+01,\n",
       "        3.61443074e-01,  5.96704461e-01, -1.46616634e+01,  1.58280943e+00,\n",
       "       -1.97270177e+01,  1.72092559e+00, -8.35462382e+00,  4.43128660e-01,\n",
       "        3.34228768e+00,  5.17472237e-01, -2.43646526e+00, -3.42637604e-01,\n",
       "       -8.53840647e+00, -2.57599971e+01, -5.75233417e+00, -2.12985471e-01,\n",
       "       -2.23775324e-01, -7.72604720e+00, -8.77095680e-01, -1.26001964e+00,\n",
       "        6.99921706e-01,  2.39040501e-01,  1.35030363e+00, -2.02903988e+00,\n",
       "       -3.36449827e+00, -2.92641362e+00, -7.95121437e-01,  4.26427751e-01,\n",
       "       -4.21798037e+00, -1.97829544e+00, -1.71501898e-01, -5.75977849e+00,\n",
       "       -1.22015504e+00, -2.88327905e-01, -4.17460211e+00,  1.12891536e+00,\n",
       "        2.83529466e-01, -2.21899622e+00, -9.79005311e+00, -8.21646636e+00,\n",
       "       -4.29964243e+00, -1.93958745e+00, -8.66777701e+00, -4.20747046e+00,\n",
       "       -4.12890917e+00, -6.10613367e-01, -1.03579037e-01, -1.63440987e+00,\n",
       "        1.87965853e+00, -3.70665144e+00,  6.24062154e-01,  2.84129380e-01,\n",
       "       -3.97621778e+00,  9.03794236e-01, -8.22606376e+00, -2.73145826e+00,\n",
       "        7.59748986e-01, -2.61565959e+00,  2.08837143e-02, -4.59591061e+00,\n",
       "        1.81746578e+00,  3.68612629e-01, -8.00470486e+00, -1.14373176e+01,\n",
       "       -4.16976316e+00,  2.65751366e+00, -8.09751696e-02, -7.29756038e-01,\n",
       "       -1.02282674e+00,  8.37977000e-01,  8.42365601e-01, -3.15659969e+00,\n",
       "       -1.07448779e+00, -1.29545904e+00, -8.51714295e-01,  3.13057458e-01,\n",
       "       -8.02315328e-01, -6.88313227e+00,  4.86703073e+00, -4.05988916e+00,\n",
       "       -7.25795722e-01,  1.30085921e+00,  1.35786079e+00, -1.00395129e+00,\n",
       "       -2.77639118e+00, -6.36561176e+00, -1.00097930e+01, -4.89728623e+00,\n",
       "       -2.03874358e+00, -5.90949615e-03, -7.53673052e+00, -5.02729397e-01,\n",
       "       -2.47611827e-01, -5.69743769e+00, -7.29528731e-01, -8.86809302e-01,\n",
       "       -3.32524783e+00,  2.74425009e+00, -6.53582099e+00, -1.15020927e+01,\n",
       "        7.36038209e-01, -6.58624038e+00, -2.17926839e+00, -5.61791771e+00,\n",
       "       -3.43626574e+00, -2.14143890e+00,  2.05563668e+00, -1.06932184e+01,\n",
       "       -1.65509544e+00, -4.18537631e+00, -2.06803119e+01, -1.94286352e+00,\n",
       "       -1.01736336e+01, -8.19544647e+00, -3.57335102e+00, -3.96211067e+00,\n",
       "       -1.56797217e+00, -9.97139353e+00, -6.36697113e-01, -1.35439503e+00,\n",
       "       -1.08039445e+00,  2.07160072e+00,  1.33497918e+00, -7.74477169e-01,\n",
       "       -2.93081004e+00,  1.46768156e+00, -4.02609531e+00, -4.70694046e+00,\n",
       "       -1.38532291e+01, -3.69623693e+00, -5.80943971e+00,  1.91407983e+00,\n",
       "       -7.51201490e-01, -4.46138667e+00, -4.38193683e+00, -6.67265691e+00,\n",
       "        2.79710852e+00,  5.30741058e-01, -5.77093870e+00, -6.70761949e+00,\n",
       "       -4.46747041e+00, -1.82251031e+00,  7.01505044e-01, -4.42071712e+00,\n",
       "       -2.73694283e-01,  7.46857248e-01,  1.07622772e+00, -2.04653309e+00,\n",
       "       -3.93420342e+00, -1.01435082e+00,  8.60374630e-02, -6.68201451e+00,\n",
       "        8.52230085e-02,  1.01220814e+00, -2.49325497e+00, -3.24841139e-02,\n",
       "        6.69108275e-01, -8.76112674e+00, -2.09265927e+00, -2.76287453e+00,\n",
       "        3.74895124e+00, -1.34089569e+00,  3.98707496e+00, -1.25847062e+01,\n",
       "       -1.18674283e+00, -8.72186606e+00, -1.69005714e+00, -1.13342980e+00,\n",
       "        2.05662627e-01, -1.17998815e+00, -3.63759940e-01, -7.52534472e+00,\n",
       "        4.62517363e-01,  5.18105682e-01,  1.24111058e+00,  1.40843771e+00,\n",
       "       -7.68135010e+00, -1.56658836e+00, -7.45070576e-01,  9.30957315e-01,\n",
       "       -1.23302521e+00, -1.09305099e+01, -8.81462315e-01, -3.17194855e+00,\n",
       "        9.04232967e-01,  2.85283283e-01, -1.49832144e+01, -5.37934797e+00,\n",
       "       -7.91441525e+00, -1.74268316e+00,  4.50887348e-01, -5.74550767e+00,\n",
       "        7.07802245e-01,  5.85983028e-01, -5.51849041e-01, -2.90021221e+00,\n",
       "       -8.27881347e+00, -1.50356966e+00,  1.11210825e+00,  1.32442077e+00,\n",
       "       -1.10561848e+01, -4.62304681e-01, -4.99478399e+00, -3.82331067e+00,\n",
       "       -8.12576054e-01,  2.20420725e-01,  1.29929586e+00,  5.38470440e-01,\n",
       "       -3.87637006e-02, -3.00076684e+00,  1.35534324e+00, -6.57836814e+00,\n",
       "        1.09358678e+00, -1.09301511e+00, -9.61639035e+00,  2.15603211e+00,\n",
       "        1.40565425e+00,  4.54026626e-01,  1.36778474e+00,  3.87443548e-01,\n",
       "       -1.50793740e+00, -1.46128671e+00,  1.45555291e-01, -9.54734595e-01,\n",
       "       -1.89484377e-01,  4.02170079e-01, -1.13903112e+00, -6.23199884e+00,\n",
       "       -1.05222826e+00,  1.20521064e+00,  1.62345259e+00, -5.55967979e+00,\n",
       "       -1.66753237e+01, -6.07931593e-03, -2.92525635e+00, -2.37878069e+00,\n",
       "        1.28808712e+00, -3.57698745e+00, -1.06760334e+01, -2.48999268e+00,\n",
       "        7.73387996e-02, -2.21882195e+00,  1.44545438e+00, -1.02882490e+01,\n",
       "       -1.00754660e+01, -4.00576330e+00,  4.68664871e-01, -5.51620573e+00,\n",
       "       -4.23150862e+00, -5.21900597e-02, -4.31997765e+00, -3.06063865e+00,\n",
       "        4.04208571e-01,  1.12305800e-01, -6.37957079e+00,  9.22849135e-01,\n",
       "        7.67985134e-01, -6.66446404e+00, -1.41663018e+01, -8.72432938e+00,\n",
       "       -3.84058355e+00, -3.19080834e+00, -7.43417221e-01,  4.77403416e-01,\n",
       "       -8.75220892e+00, -1.02649295e+01, -1.19243946e+00,  7.34423690e-02,\n",
       "       -7.09607936e+00, -8.69525883e+00, -8.15942688e+00, -6.11549898e+00,\n",
       "       -5.74778445e+00, -8.15883087e+00,  2.10975308e+00, -5.23756576e+00,\n",
       "        2.56992149e-01, -8.67818771e+00,  1.50570626e-01, -4.39582485e+00,\n",
       "       -1.46316571e-01,  1.54545613e+00, -7.61912407e+00,  8.54530726e-01,\n",
       "       -5.69002964e-01, -1.29036863e+01, -5.20072641e-01,  1.69057248e+00,\n",
       "        1.66469915e+00, -2.00719292e+00, -6.23813280e+00,  2.28988461e-01])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:06:03.004110Z",
     "start_time": "2019-03-07T14:06:02.997854Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_likelihood(params):\n",
    "    predictions = make_predictions(params)\n",
    "    return np.sum(norm.logpdf(predictions, loc=expt_means[train_inds], scale=expt_uncs[train_inds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:06:03.586837Z",
     "start_time": "2019-03-07T14:06:03.581736Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_posterior(params):\n",
    "    return log_prior(params) + log_likelihood(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:06:04.698622Z",
     "start_time": "2019-03-07T14:06:04.053321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-54579.52569068625"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_posterior(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:06:15.009868Z",
     "start_time": "2019-03-07T14:06:04.702647Z"
    }
   },
   "outputs": [],
   "source": [
    "from autograd import grad\n",
    "g = grad(log_posterior)(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:06:15.017693Z",
     "start_time": "2019-03-07T14:06:15.013216Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(x, y):\n",
    "    squared_errors = (x - y)**2\n",
    "    mean_squared_errors = np.mean(squared_errors)\n",
    "    root_mean_squared_errors = np.sqrt(mean_squared_errors)\n",
    "    return root_mean_squared_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:20:08.217549Z",
     "start_time": "2019-03-07T14:06:18.922813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters\n",
      "\ttrain RMSE = 3.622\n",
      "\ttest RMSE = 3.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuafass/anaconda3/lib/python3.7/site-packages/autograd/numpy/numpy_vjps.py:444: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return lambda g: g[idxs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "\ttrain RMSE = 3.577\n",
      "\ttest RMSE = 3.361\n",
      "Iteration 1\n",
      "\ttrain RMSE = 3.384\n",
      "\ttest RMSE = 3.172\n",
      "Iteration 2\n",
      "\ttrain RMSE = 3.286\n",
      "\ttest RMSE = 3.155\n",
      "Iteration 3\n",
      "\ttrain RMSE = 3.258\n",
      "\ttest RMSE = 3.116\n",
      "Iteration 4\n",
      "\ttrain RMSE = 3.227\n",
      "\ttest RMSE = 3.030\n",
      "Iteration 5\n",
      "\ttrain RMSE = 3.135\n",
      "\ttest RMSE = 2.967\n",
      "Iteration 6\n",
      "\ttrain RMSE = 3.051\n",
      "\ttest RMSE = 2.894\n",
      "Iteration 7\n",
      "\ttrain RMSE = 2.944\n",
      "\ttest RMSE = 2.742\n",
      "Iteration 8\n",
      "\ttrain RMSE = 2.976\n",
      "\ttest RMSE = 2.641\n",
      "Iteration 9\n",
      "\ttrain RMSE = 2.991\n",
      "\ttest RMSE = 2.602\n",
      "Iteration 10\n",
      "\ttrain RMSE = 2.907\n",
      "\ttest RMSE = 2.538\n",
      "Iteration 11\n",
      "\ttrain RMSE = 2.796\n",
      "\ttest RMSE = 2.508\n",
      "Iteration 12\n",
      "\ttrain RMSE = 2.677\n",
      "\ttest RMSE = 2.335\n",
      "Iteration 13\n",
      "\ttrain RMSE = 2.580\n",
      "\ttest RMSE = 2.287\n",
      "Iteration 14\n",
      "\ttrain RMSE = 2.480\n",
      "\ttest RMSE = 2.246\n",
      "Iteration 15\n",
      "\ttrain RMSE = 2.451\n",
      "\ttest RMSE = 2.250\n",
      "Iteration 16\n",
      "\ttrain RMSE = 2.469\n",
      "\ttest RMSE = 2.246\n",
      "Iteration 17\n",
      "\ttrain RMSE = 2.401\n",
      "\ttest RMSE = 2.327\n",
      "Iteration 18\n",
      "\ttrain RMSE = 2.399\n",
      "\ttest RMSE = 2.359\n",
      "Iteration 19\n",
      "\ttrain RMSE = 2.360\n",
      "\ttest RMSE = 2.377\n",
      "Iteration 20\n",
      "\ttrain RMSE = 2.322\n",
      "\ttest RMSE = 2.359\n",
      "Iteration 21\n",
      "\ttrain RMSE = 2.296\n",
      "\ttest RMSE = 2.363\n",
      "Iteration 22\n",
      "\ttrain RMSE = 2.243\n",
      "\ttest RMSE = 2.364\n",
      "Iteration 23\n",
      "\ttrain RMSE = 2.256\n",
      "\ttest RMSE = 2.370\n",
      "Iteration 24\n",
      "\ttrain RMSE = 2.232\n",
      "\ttest RMSE = 2.414\n",
      "Iteration 25\n",
      "\ttrain RMSE = 2.267\n",
      "\ttest RMSE = 2.477\n",
      "Iteration 26\n",
      "\ttrain RMSE = 2.312\n",
      "\ttest RMSE = 2.515\n",
      "Iteration 27\n",
      "\ttrain RMSE = 2.272\n",
      "\ttest RMSE = 2.571\n",
      "Iteration 28\n",
      "\ttrain RMSE = 2.249\n",
      "\ttest RMSE = 2.581\n",
      "Iteration 29\n",
      "\ttrain RMSE = 2.212\n",
      "\ttest RMSE = 2.540\n",
      "Iteration 30\n",
      "\ttrain RMSE = 2.219\n",
      "\ttest RMSE = 2.583\n",
      "Iteration 31\n",
      "\ttrain RMSE = 2.259\n",
      "\ttest RMSE = 2.602\n",
      "Iteration 32\n",
      "\ttrain RMSE = 2.241\n",
      "\ttest RMSE = 2.615\n",
      "Iteration 33\n",
      "\ttrain RMSE = 2.245\n",
      "\ttest RMSE = 2.588\n",
      "Iteration 34\n",
      "\ttrain RMSE = 2.237\n",
      "\ttest RMSE = 2.561\n",
      "Iteration 35\n",
      "\ttrain RMSE = 2.174\n",
      "\ttest RMSE = 2.512\n",
      "Iteration 36\n",
      "\ttrain RMSE = 2.152\n",
      "\ttest RMSE = 2.438\n",
      "Iteration 37\n",
      "\ttrain RMSE = 2.098\n",
      "\ttest RMSE = 2.354\n",
      "Iteration 38\n",
      "\ttrain RMSE = 2.120\n",
      "\ttest RMSE = 2.375\n",
      "Iteration 39\n",
      "\ttrain RMSE = 2.119\n",
      "\ttest RMSE = 2.274\n",
      "Iteration 40\n",
      "\ttrain RMSE = 2.117\n",
      "\ttest RMSE = 2.316\n",
      "Iteration 41\n",
      "\ttrain RMSE = 2.117\n",
      "\ttest RMSE = 2.258\n",
      "Iteration 42\n",
      "\ttrain RMSE = 2.074\n",
      "\ttest RMSE = 2.161\n",
      "Iteration 43\n",
      "\ttrain RMSE = 2.026\n",
      "\ttest RMSE = 2.060\n",
      "Iteration 44\n",
      "\ttrain RMSE = 1.992\n",
      "\ttest RMSE = 2.061\n",
      "Iteration 45\n",
      "\ttrain RMSE = 1.946\n",
      "\ttest RMSE = 1.981\n",
      "Iteration 46\n",
      "\ttrain RMSE = 1.956\n",
      "\ttest RMSE = 1.964\n",
      "Iteration 47\n",
      "\ttrain RMSE = 1.954\n",
      "\ttest RMSE = 1.964\n",
      "Iteration 48\n",
      "\ttrain RMSE = 1.929\n",
      "\ttest RMSE = 1.946\n",
      "Iteration 49\n",
      "\ttrain RMSE = 1.958\n",
      "\ttest RMSE = 1.903\n",
      "Iteration 50\n",
      "\ttrain RMSE = 1.903\n",
      "\ttest RMSE = 1.880\n",
      "Iteration 51\n",
      "\ttrain RMSE = 1.924\n",
      "\ttest RMSE = 1.855\n",
      "Iteration 52\n",
      "\ttrain RMSE = 1.882\n",
      "\ttest RMSE = 1.820\n",
      "Iteration 53\n",
      "\ttrain RMSE = 1.878\n",
      "\ttest RMSE = 1.811\n",
      "Iteration 54\n",
      "\ttrain RMSE = 1.844\n",
      "\ttest RMSE = 1.741\n",
      "Iteration 55\n",
      "\ttrain RMSE = 1.854\n",
      "\ttest RMSE = 1.787\n",
      "Iteration 56\n",
      "\ttrain RMSE = 1.858\n",
      "\ttest RMSE = 1.746\n",
      "Iteration 57\n",
      "\ttrain RMSE = 1.875\n",
      "\ttest RMSE = 1.752\n",
      "Iteration 58\n",
      "\ttrain RMSE = 1.872\n",
      "\ttest RMSE = 1.758\n",
      "Iteration 59\n",
      "\ttrain RMSE = 1.872\n",
      "\ttest RMSE = 1.728\n",
      "Iteration 60\n",
      "\ttrain RMSE = 1.852\n",
      "\ttest RMSE = 1.715\n",
      "Iteration 61\n",
      "\ttrain RMSE = 1.835\n",
      "\ttest RMSE = 1.732\n",
      "Iteration 62\n",
      "\ttrain RMSE = 1.842\n",
      "\ttest RMSE = 1.786\n",
      "Iteration 63\n",
      "\ttrain RMSE = 1.867\n",
      "\ttest RMSE = 1.776\n",
      "Iteration 64\n",
      "\ttrain RMSE = 1.869\n",
      "\ttest RMSE = 1.779\n",
      "Iteration 65\n",
      "\ttrain RMSE = 1.862\n",
      "\ttest RMSE = 1.806\n",
      "Iteration 66\n",
      "\ttrain RMSE = 1.829\n",
      "\ttest RMSE = 1.799\n",
      "Iteration 67\n",
      "\ttrain RMSE = 1.832\n",
      "\ttest RMSE = 1.762\n",
      "Iteration 68\n",
      "\ttrain RMSE = 1.828\n",
      "\ttest RMSE = 1.766\n",
      "Iteration 69\n",
      "\ttrain RMSE = 1.820\n",
      "\ttest RMSE = 1.740\n",
      "Iteration 70\n",
      "\ttrain RMSE = 1.834\n",
      "\ttest RMSE = 1.786\n",
      "Iteration 71\n",
      "\ttrain RMSE = 1.872\n",
      "\ttest RMSE = 1.772\n",
      "Iteration 72\n",
      "\ttrain RMSE = 1.811\n",
      "\ttest RMSE = 1.798\n",
      "Iteration 73\n",
      "\ttrain RMSE = 1.823\n",
      "\ttest RMSE = 1.758\n",
      "Iteration 74\n",
      "\ttrain RMSE = 1.823\n",
      "\ttest RMSE = 1.741\n",
      "Iteration 75\n",
      "\ttrain RMSE = 1.810\n",
      "\ttest RMSE = 1.745\n",
      "Iteration 76\n",
      "\ttrain RMSE = 1.779\n",
      "\ttest RMSE = 1.795\n",
      "Iteration 77\n",
      "\ttrain RMSE = 1.772\n",
      "\ttest RMSE = 1.759\n",
      "Iteration 78\n",
      "\ttrain RMSE = 1.813\n",
      "\ttest RMSE = 1.742\n",
      "Iteration 79\n",
      "\ttrain RMSE = 1.817\n",
      "\ttest RMSE = 1.793\n",
      "Iteration 80\n",
      "\ttrain RMSE = 1.874\n",
      "\ttest RMSE = 1.832\n",
      "Iteration 81\n",
      "\ttrain RMSE = 1.804\n",
      "\ttest RMSE = 1.769\n",
      "Iteration 82\n",
      "\ttrain RMSE = 1.814\n",
      "\ttest RMSE = 1.762\n",
      "Iteration 83\n",
      "\ttrain RMSE = 1.801\n",
      "\ttest RMSE = 1.761\n",
      "Iteration 84\n",
      "\ttrain RMSE = 1.774\n",
      "\ttest RMSE = 1.733\n",
      "Iteration 85\n",
      "\ttrain RMSE = 1.766\n",
      "\ttest RMSE = 1.725\n",
      "Iteration 86\n",
      "\ttrain RMSE = 1.828\n",
      "\ttest RMSE = 1.723\n",
      "Iteration 87\n",
      "\ttrain RMSE = 1.773\n",
      "\ttest RMSE = 1.767\n",
      "Iteration 88\n",
      "\ttrain RMSE = 1.797\n",
      "\ttest RMSE = 1.743\n",
      "Iteration 89\n",
      "\ttrain RMSE = 1.805\n",
      "\ttest RMSE = 1.751\n",
      "Iteration 90\n",
      "\ttrain RMSE = 1.777\n",
      "\ttest RMSE = 1.744\n",
      "Iteration 91\n",
      "\ttrain RMSE = 1.803\n",
      "\ttest RMSE = 1.720\n",
      "Iteration 92\n",
      "\ttrain RMSE = 1.789\n",
      "\ttest RMSE = 1.703\n",
      "Iteration 93\n",
      "\ttrain RMSE = 1.805\n",
      "\ttest RMSE = 1.684\n",
      "Iteration 94\n",
      "\ttrain RMSE = 1.757\n",
      "\ttest RMSE = 1.723\n",
      "Iteration 95\n",
      "\ttrain RMSE = 1.772\n",
      "\ttest RMSE = 1.709\n",
      "Iteration 96\n",
      "\ttrain RMSE = 1.826\n",
      "\ttest RMSE = 1.747\n",
      "Iteration 97\n",
      "\ttrain RMSE = 1.825\n",
      "\ttest RMSE = 1.745\n",
      "Iteration 98\n",
      "\ttrain RMSE = 1.821\n",
      "\ttest RMSE = 1.734\n",
      "Iteration 99\n",
      "\ttrain RMSE = 1.763\n",
      "\ttest RMSE = 1.709\n",
      "Iteration 100\n",
      "\ttrain RMSE = 1.781\n",
      "\ttest RMSE = 1.741\n",
      "Iteration 101\n",
      "\ttrain RMSE = 1.817\n",
      "\ttest RMSE = 1.722\n",
      "Iteration 102\n",
      "\ttrain RMSE = 1.748\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 103\n",
      "\ttrain RMSE = 1.738\n",
      "\ttest RMSE = 1.686\n",
      "Iteration 104\n",
      "\ttrain RMSE = 1.773\n",
      "\ttest RMSE = 1.696\n",
      "Iteration 105\n",
      "\ttrain RMSE = 1.744\n",
      "\ttest RMSE = 1.682\n",
      "Iteration 106\n",
      "\ttrain RMSE = 1.775\n",
      "\ttest RMSE = 1.692\n",
      "Iteration 107\n",
      "\ttrain RMSE = 1.800\n",
      "\ttest RMSE = 1.667\n",
      "Iteration 108\n",
      "\ttrain RMSE = 1.762\n",
      "\ttest RMSE = 1.698\n",
      "Iteration 109\n",
      "\ttrain RMSE = 1.733\n",
      "\ttest RMSE = 1.696\n",
      "Iteration 110\n",
      "\ttrain RMSE = 1.760\n",
      "\ttest RMSE = 1.671\n",
      "Iteration 111\n",
      "\ttrain RMSE = 1.740\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 112\n",
      "\ttrain RMSE = 1.744\n",
      "\ttest RMSE = 1.691\n",
      "Iteration 113\n",
      "\ttrain RMSE = 1.757\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 114\n",
      "\ttrain RMSE = 1.736\n",
      "\ttest RMSE = 1.730\n",
      "Iteration 115\n",
      "\ttrain RMSE = 1.751\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 116\n",
      "\ttrain RMSE = 1.772\n",
      "\ttest RMSE = 1.715\n",
      "Iteration 117\n",
      "\ttrain RMSE = 1.806\n",
      "\ttest RMSE = 1.685\n",
      "Iteration 118\n",
      "\ttrain RMSE = 1.769\n",
      "\ttest RMSE = 1.702\n",
      "Iteration 119\n",
      "\ttrain RMSE = 1.735\n",
      "\ttest RMSE = 1.699\n",
      "Iteration 120\n",
      "\ttrain RMSE = 1.721\n",
      "\ttest RMSE = 1.692\n",
      "Iteration 121\n",
      "\ttrain RMSE = 1.728\n",
      "\ttest RMSE = 1.695\n",
      "Iteration 122\n",
      "\ttrain RMSE = 1.766\n",
      "\ttest RMSE = 1.698\n",
      "Iteration 123\n",
      "\ttrain RMSE = 1.707\n",
      "\ttest RMSE = 1.710\n",
      "Iteration 124\n",
      "\ttrain RMSE = 1.790\n",
      "\ttest RMSE = 1.709\n",
      "Iteration 125\n",
      "\ttrain RMSE = 1.716\n",
      "\ttest RMSE = 1.701\n",
      "Iteration 126\n",
      "\ttrain RMSE = 1.767\n",
      "\ttest RMSE = 1.714\n",
      "Iteration 127\n",
      "\ttrain RMSE = 1.807\n",
      "\ttest RMSE = 1.686\n",
      "Iteration 128\n",
      "\ttrain RMSE = 1.677\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 129\n",
      "\ttrain RMSE = 1.766\n",
      "\ttest RMSE = 1.702\n",
      "Iteration 130\n",
      "\ttrain RMSE = 1.711\n",
      "\ttest RMSE = 1.705\n",
      "Iteration 131\n",
      "\ttrain RMSE = 1.763\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 132\n",
      "\ttrain RMSE = 1.746\n",
      "\ttest RMSE = 1.677\n",
      "Iteration 133\n",
      "\ttrain RMSE = 1.733\n",
      "\ttest RMSE = 1.676\n",
      "Iteration 134\n",
      "\ttrain RMSE = 1.715\n",
      "\ttest RMSE = 1.692\n",
      "Iteration 135\n",
      "\ttrain RMSE = 1.692\n",
      "\ttest RMSE = 1.671\n",
      "Iteration 136\n",
      "\ttrain RMSE = 1.697\n",
      "\ttest RMSE = 1.678\n",
      "Iteration 137\n",
      "\ttrain RMSE = 1.706\n",
      "\ttest RMSE = 1.662\n",
      "Iteration 138\n",
      "\ttrain RMSE = 1.693\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 139\n",
      "\ttrain RMSE = 1.702\n",
      "\ttest RMSE = 1.649\n",
      "Iteration 140\n",
      "\ttrain RMSE = 1.737\n",
      "\ttest RMSE = 1.692\n",
      "Iteration 141\n",
      "\ttrain RMSE = 1.729\n",
      "\ttest RMSE = 1.651\n",
      "Iteration 142\n",
      "\ttrain RMSE = 1.633\n",
      "\ttest RMSE = 1.664\n",
      "Iteration 143\n",
      "\ttrain RMSE = 1.653\n",
      "\ttest RMSE = 1.658\n",
      "Iteration 144\n",
      "\ttrain RMSE = 1.717\n",
      "\ttest RMSE = 1.675\n",
      "Iteration 145\n",
      "\ttrain RMSE = 1.701\n",
      "\ttest RMSE = 1.660\n",
      "Iteration 146\n",
      "\ttrain RMSE = 1.714\n",
      "\ttest RMSE = 1.656\n",
      "Iteration 147\n",
      "\ttrain RMSE = 1.671\n",
      "\ttest RMSE = 1.653\n",
      "Iteration 148\n",
      "\ttrain RMSE = 1.673\n",
      "\ttest RMSE = 1.685\n",
      "Iteration 149\n",
      "\ttrain RMSE = 1.658\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 150\n",
      "\ttrain RMSE = 1.698\n",
      "\ttest RMSE = 1.684\n",
      "Iteration 151\n",
      "\ttrain RMSE = 1.639\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 152\n",
      "\ttrain RMSE = 1.714\n",
      "\ttest RMSE = 1.669\n",
      "Iteration 153\n",
      "\ttrain RMSE = 1.715\n",
      "\ttest RMSE = 1.679\n",
      "Iteration 154\n",
      "\ttrain RMSE = 1.708\n",
      "\ttest RMSE = 1.681\n",
      "Iteration 155\n",
      "\ttrain RMSE = 1.657\n",
      "\ttest RMSE = 1.683\n",
      "Iteration 156\n",
      "\ttrain RMSE = 1.649\n",
      "\ttest RMSE = 1.682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 157\n",
      "\ttrain RMSE = 1.675\n",
      "\ttest RMSE = 1.700\n",
      "Iteration 158\n",
      "\ttrain RMSE = 1.698\n",
      "\ttest RMSE = 1.679\n",
      "Iteration 159\n",
      "\ttrain RMSE = 1.710\n",
      "\ttest RMSE = 1.676\n",
      "Iteration 160\n",
      "\ttrain RMSE = 1.641\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 161\n",
      "\ttrain RMSE = 1.673\n",
      "\ttest RMSE = 1.671\n",
      "Iteration 162\n",
      "\ttrain RMSE = 1.682\n",
      "\ttest RMSE = 1.708\n",
      "Iteration 163\n",
      "\ttrain RMSE = 1.715\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 164\n",
      "\ttrain RMSE = 1.647\n",
      "\ttest RMSE = 1.687\n",
      "Iteration 165\n",
      "\ttrain RMSE = 1.677\n",
      "\ttest RMSE = 1.671\n",
      "Iteration 166\n",
      "\ttrain RMSE = 1.688\n",
      "\ttest RMSE = 1.687\n",
      "Iteration 167\n",
      "\ttrain RMSE = 1.749\n",
      "\ttest RMSE = 1.740\n",
      "Iteration 168\n",
      "\ttrain RMSE = 1.755\n",
      "\ttest RMSE = 1.727\n",
      "Iteration 169\n",
      "\ttrain RMSE = 1.632\n",
      "\ttest RMSE = 1.715\n",
      "Iteration 170\n",
      "\ttrain RMSE = 1.695\n",
      "\ttest RMSE = 1.682\n",
      "Iteration 171\n",
      "\ttrain RMSE = 1.754\n",
      "\ttest RMSE = 1.676\n",
      "Iteration 172\n",
      "\ttrain RMSE = 1.690\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 173\n",
      "\ttrain RMSE = 1.678\n",
      "\ttest RMSE = 1.704\n",
      "Iteration 174\n",
      "\ttrain RMSE = 1.719\n",
      "\ttest RMSE = 1.683\n",
      "Iteration 175\n",
      "\ttrain RMSE = 1.622\n",
      "\ttest RMSE = 1.687\n",
      "Iteration 176\n",
      "\ttrain RMSE = 1.628\n",
      "\ttest RMSE = 1.679\n",
      "Iteration 177\n",
      "\ttrain RMSE = 1.709\n",
      "\ttest RMSE = 1.696\n",
      "Iteration 178\n",
      "\ttrain RMSE = 1.661\n",
      "\ttest RMSE = 1.666\n",
      "Iteration 179\n",
      "\ttrain RMSE = 1.679\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 180\n",
      "\ttrain RMSE = 1.648\n",
      "\ttest RMSE = 1.654\n",
      "Iteration 181\n",
      "\ttrain RMSE = 1.608\n",
      "\ttest RMSE = 1.655\n",
      "Iteration 182\n",
      "\ttrain RMSE = 1.692\n",
      "\ttest RMSE = 1.662\n",
      "Iteration 183\n",
      "\ttrain RMSE = 1.656\n",
      "\ttest RMSE = 1.666\n",
      "Iteration 184\n",
      "\ttrain RMSE = 1.651\n",
      "\ttest RMSE = 1.651\n",
      "Iteration 185\n",
      "\ttrain RMSE = 1.685\n",
      "\ttest RMSE = 1.677\n",
      "Iteration 186\n",
      "\ttrain RMSE = 1.644\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 187\n",
      "\ttrain RMSE = 1.684\n",
      "\ttest RMSE = 1.677\n",
      "Iteration 188\n",
      "\ttrain RMSE = 1.689\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 189\n",
      "\ttrain RMSE = 1.658\n",
      "\ttest RMSE = 1.655\n",
      "Iteration 190\n",
      "\ttrain RMSE = 1.640\n",
      "\ttest RMSE = 1.653\n",
      "Iteration 191\n",
      "\ttrain RMSE = 1.683\n",
      "\ttest RMSE = 1.715\n",
      "Iteration 192\n",
      "\ttrain RMSE = 1.671\n",
      "\ttest RMSE = 1.713\n",
      "Iteration 193\n",
      "\ttrain RMSE = 1.654\n",
      "\ttest RMSE = 1.665\n",
      "Iteration 194\n",
      "\ttrain RMSE = 1.703\n",
      "\ttest RMSE = 1.655\n",
      "Iteration 195\n",
      "\ttrain RMSE = 1.698\n",
      "\ttest RMSE = 1.677\n",
      "Iteration 196\n",
      "\ttrain RMSE = 1.703\n",
      "\ttest RMSE = 1.708\n",
      "Iteration 197\n",
      "\ttrain RMSE = 1.665\n",
      "\ttest RMSE = 1.657\n",
      "Iteration 198\n",
      "\ttrain RMSE = 1.666\n",
      "\ttest RMSE = 1.668\n",
      "Iteration 199\n",
      "\ttrain RMSE = 1.668\n",
      "\ttest RMSE = 1.666\n",
      "Iteration 200\n",
      "\ttrain RMSE = 1.691\n",
      "\ttest RMSE = 1.674\n",
      "Iteration 201\n",
      "\ttrain RMSE = 1.697\n",
      "\ttest RMSE = 1.687\n",
      "Iteration 202\n",
      "\ttrain RMSE = 1.660\n",
      "\ttest RMSE = 1.687\n",
      "Iteration 203\n",
      "\ttrain RMSE = 1.676\n",
      "\ttest RMSE = 1.691\n",
      "Iteration 204\n",
      "\ttrain RMSE = 1.673\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 205\n",
      "\ttrain RMSE = 1.698\n",
      "\ttest RMSE = 1.667\n",
      "Iteration 206\n",
      "\ttrain RMSE = 1.708\n",
      "\ttest RMSE = 1.669\n",
      "Iteration 207\n",
      "\ttrain RMSE = 1.659\n",
      "\ttest RMSE = 1.654\n",
      "Iteration 208\n",
      "\ttrain RMSE = 1.598\n",
      "\ttest RMSE = 1.668\n",
      "Iteration 209\n",
      "\ttrain RMSE = 1.616\n",
      "\ttest RMSE = 1.663\n",
      "Iteration 210\n",
      "\ttrain RMSE = 1.704\n",
      "\ttest RMSE = 1.714\n",
      "Iteration 211\n",
      "\ttrain RMSE = 1.704\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 212\n",
      "\ttrain RMSE = 1.656\n",
      "\ttest RMSE = 1.652\n",
      "Iteration 213\n",
      "\ttrain RMSE = 1.642\n",
      "\ttest RMSE = 1.660\n",
      "Iteration 214\n",
      "\ttrain RMSE = 1.710\n",
      "\ttest RMSE = 1.661\n",
      "Iteration 215\n",
      "\ttrain RMSE = 1.640\n",
      "\ttest RMSE = 1.654\n",
      "Iteration 216\n",
      "\ttrain RMSE = 1.636\n",
      "\ttest RMSE = 1.689\n",
      "Iteration 217\n",
      "\ttrain RMSE = 1.696\n",
      "\ttest RMSE = 1.660\n",
      "Iteration 218\n",
      "\ttrain RMSE = 1.737\n",
      "\ttest RMSE = 1.711\n",
      "Iteration 219\n",
      "\ttrain RMSE = 1.701\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 220\n",
      "\ttrain RMSE = 1.663\n",
      "\ttest RMSE = 1.666\n",
      "Iteration 221\n",
      "\ttrain RMSE = 1.638\n",
      "\ttest RMSE = 1.660\n",
      "Iteration 222\n",
      "\ttrain RMSE = 1.699\n",
      "\ttest RMSE = 1.658\n",
      "Iteration 223\n",
      "\ttrain RMSE = 1.676\n",
      "\ttest RMSE = 1.666\n",
      "Iteration 224\n",
      "\ttrain RMSE = 1.630\n",
      "\ttest RMSE = 1.652\n",
      "Iteration 225\n",
      "\ttrain RMSE = 1.671\n",
      "\ttest RMSE = 1.647\n",
      "Iteration 226\n",
      "\ttrain RMSE = 1.683\n",
      "\ttest RMSE = 1.683\n",
      "Iteration 227\n",
      "\ttrain RMSE = 1.675\n",
      "\ttest RMSE = 1.675\n",
      "Iteration 228\n",
      "\ttrain RMSE = 1.702\n",
      "\ttest RMSE = 1.701\n",
      "Iteration 229\n",
      "\ttrain RMSE = 1.671\n",
      "\ttest RMSE = 1.654\n",
      "Iteration 230\n",
      "\ttrain RMSE = 1.693\n",
      "\ttest RMSE = 1.668\n",
      "Iteration 231\n",
      "\ttrain RMSE = 1.648\n",
      "\ttest RMSE = 1.703\n",
      "Iteration 232\n",
      "\ttrain RMSE = 1.733\n",
      "\ttest RMSE = 1.712\n",
      "Iteration 233\n",
      "\ttrain RMSE = 1.692\n",
      "\ttest RMSE = 1.686\n",
      "Iteration 234\n",
      "\ttrain RMSE = 1.724\n",
      "\ttest RMSE = 1.666\n",
      "Iteration 235\n",
      "\ttrain RMSE = 1.663\n",
      "\ttest RMSE = 1.644\n",
      "Iteration 236\n",
      "\ttrain RMSE = 1.675\n",
      "\ttest RMSE = 1.658\n",
      "Iteration 237\n",
      "\ttrain RMSE = 1.689\n",
      "\ttest RMSE = 1.676\n",
      "Iteration 238\n",
      "\ttrain RMSE = 1.729\n",
      "\ttest RMSE = 1.645\n",
      "Iteration 239\n",
      "\ttrain RMSE = 1.677\n",
      "\ttest RMSE = 1.662\n",
      "Iteration 240\n",
      "\ttrain RMSE = 1.704\n",
      "\ttest RMSE = 1.664\n",
      "Iteration 241\n",
      "\ttrain RMSE = 1.692\n",
      "\ttest RMSE = 1.634\n",
      "Iteration 242\n",
      "\ttrain RMSE = 1.704\n",
      "\ttest RMSE = 1.695\n",
      "Iteration 243\n",
      "\ttrain RMSE = 1.655\n",
      "\ttest RMSE = 1.677\n",
      "Iteration 244\n",
      "\ttrain RMSE = 1.673\n",
      "\ttest RMSE = 1.665\n",
      "Iteration 245\n",
      "\ttrain RMSE = 1.655\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 246\n",
      "\ttrain RMSE = 1.649\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 247\n",
      "\ttrain RMSE = 1.622\n",
      "\ttest RMSE = 1.649\n",
      "Iteration 248\n",
      "\ttrain RMSE = 1.672\n",
      "\ttest RMSE = 1.641\n",
      "Iteration 249\n",
      "\ttrain RMSE = 1.612\n",
      "\ttest RMSE = 1.654\n",
      "Iteration 250\n",
      "\ttrain RMSE = 1.607\n",
      "\ttest RMSE = 1.651\n",
      "Iteration 251\n",
      "\ttrain RMSE = 1.670\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 252\n",
      "\ttrain RMSE = 1.684\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 253\n",
      "\ttrain RMSE = 1.680\n",
      "\ttest RMSE = 1.641\n",
      "Iteration 254\n",
      "\ttrain RMSE = 1.701\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 255\n",
      "\ttrain RMSE = 1.710\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 256\n",
      "\ttrain RMSE = 1.684\n",
      "\ttest RMSE = 1.656\n",
      "Iteration 257\n",
      "\ttrain RMSE = 1.717\n",
      "\ttest RMSE = 1.631\n",
      "Iteration 258\n",
      "\ttrain RMSE = 1.677\n",
      "\ttest RMSE = 1.643\n",
      "Iteration 259\n",
      "\ttrain RMSE = 1.662\n",
      "\ttest RMSE = 1.681\n",
      "Iteration 260\n",
      "\ttrain RMSE = 1.684\n",
      "\ttest RMSE = 1.667\n",
      "Iteration 261\n",
      "\ttrain RMSE = 1.681\n",
      "\ttest RMSE = 1.661\n",
      "Iteration 262\n",
      "\ttrain RMSE = 1.651\n",
      "\ttest RMSE = 1.625\n",
      "Iteration 263\n",
      "\ttrain RMSE = 1.701\n",
      "\ttest RMSE = 1.643\n",
      "Iteration 264\n",
      "\ttrain RMSE = 1.703\n",
      "\ttest RMSE = 1.686\n",
      "Iteration 265\n",
      "\ttrain RMSE = 1.659\n",
      "\ttest RMSE = 1.715\n",
      "Iteration 266\n",
      "\ttrain RMSE = 1.675\n",
      "\ttest RMSE = 1.681\n",
      "Iteration 267\n",
      "\ttrain RMSE = 1.660\n",
      "\ttest RMSE = 1.705\n",
      "Iteration 268\n",
      "\ttrain RMSE = 1.725\n",
      "\ttest RMSE = 1.691\n",
      "Iteration 269\n",
      "\ttrain RMSE = 1.770\n",
      "\ttest RMSE = 1.709\n",
      "Iteration 270\n",
      "\ttrain RMSE = 1.714\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 271\n",
      "\ttrain RMSE = 1.710\n",
      "\ttest RMSE = 1.663\n",
      "Iteration 272\n",
      "\ttrain RMSE = 1.692\n",
      "\ttest RMSE = 1.654\n",
      "Iteration 273\n",
      "\ttrain RMSE = 1.665\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 274\n",
      "\ttrain RMSE = 1.706\n",
      "\ttest RMSE = 1.702\n",
      "Iteration 275\n",
      "\ttrain RMSE = 1.665\n",
      "\ttest RMSE = 1.647\n",
      "Iteration 276\n",
      "\ttrain RMSE = 1.646\n",
      "\ttest RMSE = 1.648\n",
      "Iteration 277\n",
      "\ttrain RMSE = 1.675\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 278\n",
      "\ttrain RMSE = 1.689\n",
      "\ttest RMSE = 1.673\n",
      "Iteration 279\n",
      "\ttrain RMSE = 1.654\n",
      "\ttest RMSE = 1.648\n",
      "Iteration 280\n",
      "\ttrain RMSE = 1.653\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 281\n",
      "\ttrain RMSE = 1.646\n",
      "\ttest RMSE = 1.675\n",
      "Iteration 282\n",
      "\ttrain RMSE = 1.649\n",
      "\ttest RMSE = 1.640\n",
      "Iteration 283\n",
      "\ttrain RMSE = 1.661\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 284\n",
      "\ttrain RMSE = 1.740\n",
      "\ttest RMSE = 1.667\n",
      "Iteration 285\n",
      "\ttrain RMSE = 1.659\n",
      "\ttest RMSE = 1.653\n",
      "Iteration 286\n",
      "\ttrain RMSE = 1.657\n",
      "\ttest RMSE = 1.682\n",
      "Iteration 287\n",
      "\ttrain RMSE = 1.660\n",
      "\ttest RMSE = 1.649\n",
      "Iteration 288\n",
      "\ttrain RMSE = 1.708\n",
      "\ttest RMSE = 1.655\n",
      "Iteration 289\n",
      "\ttrain RMSE = 1.708\n",
      "\ttest RMSE = 1.699\n",
      "Iteration 290\n",
      "\ttrain RMSE = 1.719\n",
      "\ttest RMSE = 1.694\n",
      "Iteration 291\n",
      "\ttrain RMSE = 1.645\n",
      "\ttest RMSE = 1.649\n",
      "Iteration 292\n",
      "\ttrain RMSE = 1.655\n",
      "\ttest RMSE = 1.639\n",
      "Iteration 293\n",
      "\ttrain RMSE = 1.697\n",
      "\ttest RMSE = 1.630\n",
      "Iteration 294\n",
      "\ttrain RMSE = 1.679\n",
      "\ttest RMSE = 1.685\n",
      "Iteration 295\n",
      "\ttrain RMSE = 1.679\n",
      "\ttest RMSE = 1.644\n",
      "Iteration 296\n",
      "\ttrain RMSE = 1.632\n",
      "\ttest RMSE = 1.661\n",
      "Iteration 297\n",
      "\ttrain RMSE = 1.674\n",
      "\ttest RMSE = 1.675\n",
      "Iteration 298\n",
      "\ttrain RMSE = 1.672\n",
      "\ttest RMSE = 1.634\n",
      "Iteration 299\n",
      "\ttrain RMSE = 1.670\n",
      "\ttest RMSE = 1.689\n",
      "Iteration 300\n",
      "\ttrain RMSE = 1.661\n",
      "\ttest RMSE = 1.657\n",
      "Iteration 301\n",
      "\ttrain RMSE = 1.758\n",
      "\ttest RMSE = 1.641\n",
      "Iteration 302\n",
      "\ttrain RMSE = 1.728\n",
      "\ttest RMSE = 1.643\n",
      "Iteration 303\n",
      "\ttrain RMSE = 1.709\n",
      "\ttest RMSE = 1.614\n",
      "Iteration 304\n",
      "\ttrain RMSE = 1.637\n",
      "\ttest RMSE = 1.646\n",
      "Iteration 305\n",
      "\ttrain RMSE = 1.652\n",
      "\ttest RMSE = 1.625\n",
      "Iteration 306\n",
      "\ttrain RMSE = 1.675\n",
      "\ttest RMSE = 1.661\n",
      "Iteration 307\n",
      "\ttrain RMSE = 1.686\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 308\n",
      "\ttrain RMSE = 1.638\n",
      "\ttest RMSE = 1.687\n",
      "Iteration 309\n",
      "\ttrain RMSE = 1.696\n",
      "\ttest RMSE = 1.656\n",
      "Iteration 310\n",
      "\ttrain RMSE = 1.723\n",
      "\ttest RMSE = 1.649\n",
      "Iteration 311\n",
      "\ttrain RMSE = 1.670\n",
      "\ttest RMSE = 1.666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 312\n",
      "\ttrain RMSE = 1.687\n",
      "\ttest RMSE = 1.660\n",
      "Iteration 313\n",
      "\ttrain RMSE = 1.725\n",
      "\ttest RMSE = 1.620\n",
      "Iteration 314\n",
      "\ttrain RMSE = 1.654\n",
      "\ttest RMSE = 1.671\n",
      "Iteration 315\n",
      "\ttrain RMSE = 1.655\n",
      "\ttest RMSE = 1.638\n",
      "Iteration 316\n",
      "\ttrain RMSE = 1.719\n",
      "\ttest RMSE = 1.651\n",
      "Iteration 317\n",
      "\ttrain RMSE = 1.706\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 318\n",
      "\ttrain RMSE = 1.761\n",
      "\ttest RMSE = 1.650\n",
      "Iteration 319\n",
      "\ttrain RMSE = 1.765\n",
      "\ttest RMSE = 1.687\n",
      "Iteration 320\n",
      "\ttrain RMSE = 1.711\n",
      "\ttest RMSE = 1.686\n",
      "Iteration 321\n",
      "\ttrain RMSE = 1.673\n",
      "\ttest RMSE = 1.663\n",
      "Iteration 322\n",
      "\ttrain RMSE = 1.728\n",
      "\ttest RMSE = 1.644\n",
      "Iteration 323\n",
      "\ttrain RMSE = 1.658\n",
      "\ttest RMSE = 1.664\n",
      "Iteration 324\n",
      "\ttrain RMSE = 1.726\n",
      "\ttest RMSE = 1.630\n",
      "Iteration 325\n",
      "\ttrain RMSE = 1.680\n",
      "\ttest RMSE = 1.639\n",
      "Iteration 326\n",
      "\ttrain RMSE = 1.663\n",
      "\ttest RMSE = 1.644\n",
      "Iteration 327\n",
      "\ttrain RMSE = 1.669\n",
      "\ttest RMSE = 1.663\n",
      "Iteration 328\n",
      "\ttrain RMSE = 1.654\n",
      "\ttest RMSE = 1.632\n",
      "Iteration 329\n",
      "\ttrain RMSE = 1.715\n",
      "\ttest RMSE = 1.642\n",
      "Iteration 330\n",
      "\ttrain RMSE = 1.660\n",
      "\ttest RMSE = 1.666\n",
      "Iteration 331\n",
      "\ttrain RMSE = 1.678\n",
      "\ttest RMSE = 1.651\n",
      "Iteration 332\n",
      "\ttrain RMSE = 1.687\n",
      "\ttest RMSE = 1.655\n",
      "Iteration 333\n",
      "\ttrain RMSE = 1.704\n",
      "\ttest RMSE = 1.658\n",
      "Iteration 334\n",
      "\ttrain RMSE = 1.630\n",
      "\ttest RMSE = 1.658\n",
      "Iteration 335\n",
      "\ttrain RMSE = 1.719\n",
      "\ttest RMSE = 1.635\n",
      "Iteration 336\n",
      "\ttrain RMSE = 1.669\n",
      "\ttest RMSE = 1.630\n",
      "Iteration 337\n",
      "\ttrain RMSE = 1.733\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 338\n",
      "\ttrain RMSE = 1.681\n",
      "\ttest RMSE = 1.630\n",
      "Iteration 339\n",
      "\ttrain RMSE = 1.676\n",
      "\ttest RMSE = 1.637\n",
      "Iteration 340\n",
      "\ttrain RMSE = 1.726\n",
      "\ttest RMSE = 1.666\n",
      "Iteration 341\n",
      "\ttrain RMSE = 1.692\n",
      "\ttest RMSE = 1.710\n",
      "Iteration 342\n",
      "\ttrain RMSE = 1.750\n",
      "\ttest RMSE = 1.624\n",
      "Iteration 343\n",
      "\ttrain RMSE = 1.654\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 344\n",
      "\ttrain RMSE = 1.693\n",
      "\ttest RMSE = 1.649\n",
      "Iteration 345\n",
      "\ttrain RMSE = 1.761\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 346\n",
      "\ttrain RMSE = 1.683\n",
      "\ttest RMSE = 1.664\n",
      "Iteration 347\n",
      "\ttrain RMSE = 1.745\n",
      "\ttest RMSE = 1.639\n",
      "Iteration 348\n",
      "\ttrain RMSE = 1.739\n",
      "\ttest RMSE = 1.632\n",
      "Iteration 349\n",
      "\ttrain RMSE = 1.686\n",
      "\ttest RMSE = 1.668\n",
      "Iteration 350\n",
      "\ttrain RMSE = 1.730\n",
      "\ttest RMSE = 1.660\n",
      "Iteration 351\n",
      "\ttrain RMSE = 1.641\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 352\n",
      "\ttrain RMSE = 1.722\n",
      "\ttest RMSE = 1.679\n",
      "Iteration 353\n",
      "\ttrain RMSE = 1.718\n",
      "\ttest RMSE = 1.616\n",
      "Iteration 354\n",
      "\ttrain RMSE = 1.698\n",
      "\ttest RMSE = 1.677\n",
      "Iteration 355\n",
      "\ttrain RMSE = 1.729\n",
      "\ttest RMSE = 1.689\n",
      "Iteration 356\n",
      "\ttrain RMSE = 1.728\n",
      "\ttest RMSE = 1.648\n",
      "Iteration 357\n",
      "\ttrain RMSE = 1.742\n",
      "\ttest RMSE = 1.675\n",
      "Iteration 358\n",
      "\ttrain RMSE = 1.671\n",
      "\ttest RMSE = 1.658\n",
      "Iteration 359\n",
      "\ttrain RMSE = 1.769\n",
      "\ttest RMSE = 1.710\n",
      "Iteration 360\n",
      "\ttrain RMSE = 1.710\n",
      "\ttest RMSE = 1.708\n",
      "Iteration 361\n",
      "\ttrain RMSE = 1.705\n",
      "\ttest RMSE = 1.657\n",
      "Iteration 362\n",
      "\ttrain RMSE = 1.701\n",
      "\ttest RMSE = 1.673\n",
      "Iteration 363\n",
      "\ttrain RMSE = 1.789\n",
      "\ttest RMSE = 1.664\n",
      "Iteration 364\n",
      "\ttrain RMSE = 1.744\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 365\n",
      "\ttrain RMSE = 1.682\n",
      "\ttest RMSE = 1.682\n",
      "Iteration 366\n",
      "\ttrain RMSE = 1.743\n",
      "\ttest RMSE = 1.621\n",
      "Iteration 367\n",
      "\ttrain RMSE = 1.694\n",
      "\ttest RMSE = 1.667\n",
      "Iteration 368\n",
      "\ttrain RMSE = 1.670\n",
      "\ttest RMSE = 1.656\n",
      "Iteration 369\n",
      "\ttrain RMSE = 1.692\n",
      "\ttest RMSE = 1.642\n",
      "Iteration 370\n",
      "\ttrain RMSE = 1.687\n",
      "\ttest RMSE = 1.668\n",
      "Iteration 371\n",
      "\ttrain RMSE = 1.690\n",
      "\ttest RMSE = 1.635\n",
      "Iteration 372\n",
      "\ttrain RMSE = 1.664\n",
      "\ttest RMSE = 1.659\n",
      "Iteration 373\n",
      "\ttrain RMSE = 1.681\n",
      "\ttest RMSE = 1.660\n",
      "Iteration 374\n",
      "\ttrain RMSE = 1.690\n",
      "\ttest RMSE = 1.663\n",
      "Iteration 375\n",
      "\ttrain RMSE = 1.696\n",
      "\ttest RMSE = 1.642\n",
      "Iteration 376\n",
      "\ttrain RMSE = 1.703\n",
      "\ttest RMSE = 1.648\n",
      "Iteration 377\n",
      "\ttrain RMSE = 1.669\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 378\n",
      "\ttrain RMSE = 1.761\n",
      "\ttest RMSE = 1.664\n",
      "Iteration 379\n",
      "\ttrain RMSE = 1.691\n",
      "\ttest RMSE = 1.659\n",
      "Iteration 380\n",
      "\ttrain RMSE = 1.699\n",
      "\ttest RMSE = 1.667\n",
      "Iteration 381\n",
      "\ttrain RMSE = 1.724\n",
      "\ttest RMSE = 1.690\n",
      "Iteration 382\n",
      "\ttrain RMSE = 1.756\n",
      "\ttest RMSE = 1.651\n",
      "Iteration 383\n",
      "\ttrain RMSE = 1.738\n",
      "\ttest RMSE = 1.690\n",
      "Iteration 384\n",
      "\ttrain RMSE = 1.717\n",
      "\ttest RMSE = 1.660\n",
      "Iteration 385\n",
      "\ttrain RMSE = 1.698\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 386\n",
      "\ttrain RMSE = 1.731\n",
      "\ttest RMSE = 1.695\n",
      "Iteration 387\n",
      "\ttrain RMSE = 1.721\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 388\n",
      "\ttrain RMSE = 1.752\n",
      "\ttest RMSE = 1.665\n",
      "Iteration 389\n",
      "\ttrain RMSE = 1.687\n",
      "\ttest RMSE = 1.658\n",
      "Iteration 390\n",
      "\ttrain RMSE = 1.759\n",
      "\ttest RMSE = 1.684\n",
      "Iteration 391\n",
      "\ttrain RMSE = 1.763\n",
      "\ttest RMSE = 1.661\n",
      "Iteration 392\n",
      "\ttrain RMSE = 1.705\n",
      "\ttest RMSE = 1.681\n",
      "Iteration 393\n",
      "\ttrain RMSE = 1.728\n",
      "\ttest RMSE = 1.645\n",
      "Iteration 394\n",
      "\ttrain RMSE = 1.662\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 395\n",
      "\ttrain RMSE = 1.682\n",
      "\ttest RMSE = 1.653\n",
      "Iteration 396\n",
      "\ttrain RMSE = 1.752\n",
      "\ttest RMSE = 1.650\n",
      "Iteration 397\n",
      "\ttrain RMSE = 1.705\n",
      "\ttest RMSE = 1.654\n",
      "Iteration 398\n",
      "\ttrain RMSE = 1.679\n",
      "\ttest RMSE = 1.667\n",
      "Iteration 399\n",
      "\ttrain RMSE = 1.727\n",
      "\ttest RMSE = 1.661\n",
      "Iteration 400\n",
      "\ttrain RMSE = 1.680\n",
      "\ttest RMSE = 1.657\n",
      "Iteration 401\n",
      "\ttrain RMSE = 1.684\n",
      "\ttest RMSE = 1.685\n",
      "Iteration 402\n",
      "\ttrain RMSE = 1.689\n",
      "\ttest RMSE = 1.664\n",
      "Iteration 403\n",
      "\ttrain RMSE = 1.714\n",
      "\ttest RMSE = 1.632\n",
      "Iteration 404\n",
      "\ttrain RMSE = 1.694\n",
      "\ttest RMSE = 1.664\n",
      "Iteration 405\n",
      "\ttrain RMSE = 1.662\n",
      "\ttest RMSE = 1.669\n",
      "Iteration 406\n",
      "\ttrain RMSE = 1.767\n",
      "\ttest RMSE = 1.673\n",
      "Iteration 407\n",
      "\ttrain RMSE = 1.688\n",
      "\ttest RMSE = 1.651\n",
      "Iteration 408\n",
      "\ttrain RMSE = 1.757\n",
      "\ttest RMSE = 1.675\n",
      "Iteration 409\n",
      "\ttrain RMSE = 1.686\n",
      "\ttest RMSE = 1.656\n",
      "Iteration 410\n",
      "\ttrain RMSE = 1.648\n",
      "\ttest RMSE = 1.654\n",
      "Iteration 411\n",
      "\ttrain RMSE = 1.709\n",
      "\ttest RMSE = 1.656\n",
      "Iteration 412\n",
      "\ttrain RMSE = 1.661\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 413\n",
      "\ttrain RMSE = 1.712\n",
      "\ttest RMSE = 1.665\n",
      "Iteration 414\n",
      "\ttrain RMSE = 1.708\n",
      "\ttest RMSE = 1.683\n",
      "Iteration 415\n",
      "\ttrain RMSE = 1.783\n",
      "\ttest RMSE = 1.699\n",
      "Iteration 416\n",
      "\ttrain RMSE = 1.780\n",
      "\ttest RMSE = 1.723\n",
      "Iteration 417\n",
      "\ttrain RMSE = 1.726\n",
      "\ttest RMSE = 1.707\n",
      "Iteration 418\n",
      "\ttrain RMSE = 1.716\n",
      "\ttest RMSE = 1.687\n",
      "Iteration 419\n",
      "\ttrain RMSE = 1.708\n",
      "\ttest RMSE = 1.664\n",
      "Iteration 420\n",
      "\ttrain RMSE = 1.706\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 421\n",
      "\ttrain RMSE = 1.701\n",
      "\ttest RMSE = 1.679\n",
      "Iteration 422\n",
      "\ttrain RMSE = 1.700\n",
      "\ttest RMSE = 1.668\n",
      "Iteration 423\n",
      "\ttrain RMSE = 1.596\n",
      "\ttest RMSE = 1.663\n",
      "Iteration 424\n",
      "\ttrain RMSE = 1.710\n",
      "\ttest RMSE = 1.675\n",
      "Iteration 425\n",
      "\ttrain RMSE = 1.739\n",
      "\ttest RMSE = 1.668\n",
      "Iteration 426\n",
      "\ttrain RMSE = 1.702\n",
      "\ttest RMSE = 1.639\n",
      "Iteration 427\n",
      "\ttrain RMSE = 1.694\n",
      "\ttest RMSE = 1.652\n",
      "Iteration 428\n",
      "\ttrain RMSE = 1.687\n",
      "\ttest RMSE = 1.672\n",
      "Iteration 429\n",
      "\ttrain RMSE = 1.718\n",
      "\ttest RMSE = 1.699\n",
      "Iteration 430\n",
      "\ttrain RMSE = 1.686\n",
      "\ttest RMSE = 1.662\n",
      "Iteration 431\n",
      "\ttrain RMSE = 1.679\n",
      "\ttest RMSE = 1.687\n",
      "Iteration 432\n",
      "\ttrain RMSE = 1.780\n",
      "\ttest RMSE = 1.684\n",
      "Iteration 433\n",
      "\ttrain RMSE = 1.726\n",
      "\ttest RMSE = 1.685\n",
      "Iteration 434\n",
      "\ttrain RMSE = 1.693\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 435\n",
      "\ttrain RMSE = 1.716\n",
      "\ttest RMSE = 1.649\n",
      "Iteration 436\n",
      "\ttrain RMSE = 1.752\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 437\n",
      "\ttrain RMSE = 1.749\n",
      "\ttest RMSE = 1.676\n",
      "Iteration 438\n",
      "\ttrain RMSE = 1.713\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 439\n",
      "\ttrain RMSE = 1.683\n",
      "\ttest RMSE = 1.651\n",
      "Iteration 440\n",
      "\ttrain RMSE = 1.653\n",
      "\ttest RMSE = 1.677\n",
      "Iteration 441\n",
      "\ttrain RMSE = 1.772\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 442\n",
      "\ttrain RMSE = 1.629\n",
      "\ttest RMSE = 1.693\n",
      "Iteration 443\n",
      "\ttrain RMSE = 1.697\n",
      "\ttest RMSE = 1.719\n",
      "Iteration 444\n",
      "\ttrain RMSE = 1.675\n",
      "\ttest RMSE = 1.730\n",
      "Iteration 445\n",
      "\ttrain RMSE = 1.776\n",
      "\ttest RMSE = 1.683\n",
      "Iteration 446\n",
      "\ttrain RMSE = 1.691\n",
      "\ttest RMSE = 1.718\n",
      "Iteration 447\n",
      "\ttrain RMSE = 1.710\n",
      "\ttest RMSE = 1.682\n",
      "Iteration 448\n",
      "\ttrain RMSE = 1.700\n",
      "\ttest RMSE = 1.678\n",
      "Iteration 449\n",
      "\ttrain RMSE = 1.718\n",
      "\ttest RMSE = 1.680\n",
      "Iteration 450\n",
      "\ttrain RMSE = 1.660\n",
      "\ttest RMSE = 1.686\n",
      "Iteration 451\n",
      "\ttrain RMSE = 1.732\n",
      "\ttest RMSE = 1.645\n",
      "Iteration 452\n",
      "\ttrain RMSE = 1.606\n",
      "\ttest RMSE = 1.695\n",
      "Iteration 453\n",
      "\ttrain RMSE = 1.657\n",
      "\ttest RMSE = 1.643\n",
      "Iteration 454\n",
      "\ttrain RMSE = 1.739\n",
      "\ttest RMSE = 1.685\n",
      "Iteration 455\n",
      "\ttrain RMSE = 1.793\n",
      "\ttest RMSE = 1.673\n",
      "Iteration 456\n",
      "\ttrain RMSE = 1.670\n",
      "\ttest RMSE = 1.689\n",
      "Iteration 457\n",
      "\ttrain RMSE = 1.747\n",
      "\ttest RMSE = 1.694\n",
      "Iteration 458\n",
      "\ttrain RMSE = 1.724\n",
      "\ttest RMSE = 1.703\n",
      "Iteration 459\n",
      "\ttrain RMSE = 1.717\n",
      "\ttest RMSE = 1.681\n",
      "Iteration 460\n",
      "\ttrain RMSE = 1.710\n",
      "\ttest RMSE = 1.685\n",
      "Iteration 461\n",
      "\ttrain RMSE = 1.736\n",
      "\ttest RMSE = 1.716\n",
      "Iteration 462\n",
      "\ttrain RMSE = 1.670\n",
      "\ttest RMSE = 1.657\n",
      "Iteration 463\n",
      "\ttrain RMSE = 1.748\n",
      "\ttest RMSE = 1.679\n",
      "Iteration 464\n",
      "\ttrain RMSE = 1.685\n",
      "\ttest RMSE = 1.722\n",
      "Iteration 465\n",
      "\ttrain RMSE = 1.650\n",
      "\ttest RMSE = 1.671\n",
      "Iteration 466\n",
      "\ttrain RMSE = 1.682\n",
      "\ttest RMSE = 1.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 467\n",
      "\ttrain RMSE = 1.670\n",
      "\ttest RMSE = 1.678\n",
      "Iteration 468\n",
      "\ttrain RMSE = 1.720\n",
      "\ttest RMSE = 1.642\n",
      "Iteration 469\n",
      "\ttrain RMSE = 1.677\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 470\n",
      "\ttrain RMSE = 1.718\n",
      "\ttest RMSE = 1.670\n",
      "Iteration 471\n",
      "\ttrain RMSE = 1.737\n",
      "\ttest RMSE = 1.676\n",
      "Iteration 472\n",
      "\ttrain RMSE = 1.696\n",
      "\ttest RMSE = 1.702\n",
      "Iteration 473\n",
      "\ttrain RMSE = 1.775\n",
      "\ttest RMSE = 1.656\n",
      "Iteration 474\n",
      "\ttrain RMSE = 1.691\n",
      "\ttest RMSE = 1.690\n",
      "Iteration 475\n",
      "\ttrain RMSE = 1.742\n",
      "\ttest RMSE = 1.663\n",
      "Iteration 476\n",
      "\ttrain RMSE = 1.697\n",
      "\ttest RMSE = 1.695\n",
      "Iteration 477\n",
      "\ttrain RMSE = 1.772\n",
      "\ttest RMSE = 1.688\n",
      "Iteration 478\n",
      "\ttrain RMSE = 1.719\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 479\n",
      "\ttrain RMSE = 1.767\n",
      "\ttest RMSE = 1.697\n",
      "Iteration 480\n",
      "\ttrain RMSE = 1.700\n",
      "\ttest RMSE = 1.666\n",
      "Iteration 481\n",
      "\ttrain RMSE = 1.684\n",
      "\ttest RMSE = 1.657\n",
      "Iteration 482\n",
      "\ttrain RMSE = 1.751\n",
      "\ttest RMSE = 1.674\n",
      "Iteration 483\n",
      "\ttrain RMSE = 1.725\n",
      "\ttest RMSE = 1.688\n",
      "Iteration 484\n",
      "\ttrain RMSE = 1.707\n",
      "\ttest RMSE = 1.704\n",
      "Iteration 485\n",
      "\ttrain RMSE = 1.714\n",
      "\ttest RMSE = 1.713\n",
      "Iteration 486\n",
      "\ttrain RMSE = 1.674\n",
      "\ttest RMSE = 1.659\n",
      "Iteration 487\n",
      "\ttrain RMSE = 1.699\n",
      "\ttest RMSE = 1.679\n",
      "Iteration 488\n",
      "\ttrain RMSE = 1.703\n",
      "\ttest RMSE = 1.673\n",
      "Iteration 489\n",
      "\ttrain RMSE = 1.653\n",
      "\ttest RMSE = 1.675\n",
      "Iteration 490\n",
      "\ttrain RMSE = 1.638\n",
      "\ttest RMSE = 1.643\n",
      "Iteration 491\n",
      "\ttrain RMSE = 1.679\n",
      "\ttest RMSE = 1.637\n",
      "Iteration 492\n",
      "\ttrain RMSE = 1.648\n",
      "\ttest RMSE = 1.662\n",
      "Iteration 493\n",
      "\ttrain RMSE = 1.679\n",
      "\ttest RMSE = 1.678\n",
      "Iteration 494\n",
      "\ttrain RMSE = 1.719\n",
      "\ttest RMSE = 1.682\n",
      "Iteration 495\n",
      "\ttrain RMSE = 1.617\n",
      "\ttest RMSE = 1.673\n",
      "Iteration 496\n",
      "\ttrain RMSE = 1.709\n",
      "\ttest RMSE = 1.669\n",
      "Iteration 497\n",
      "\ttrain RMSE = 1.667\n",
      "\ttest RMSE = 1.661\n",
      "Iteration 498\n",
      "\ttrain RMSE = 1.723\n",
      "\ttest RMSE = 1.692\n",
      "Iteration 499\n",
      "\ttrain RMSE = 1.642\n",
      "\ttest RMSE = 1.664\n"
     ]
    }
   ],
   "source": [
    "from autograd.misc.optimizers import adam, sgd\n",
    "\n",
    "def loss(x):\n",
    "    return - log_posterior(x)\n",
    "\n",
    "def grad_loss(x, i):\n",
    "    return grad(loss)(x)\n",
    "\n",
    "\n",
    "traj = [(params, -1, grad_loss(params, -1))]\n",
    "prediction_traj = [make_predictions(params, inds=np.arange(len(mols)))]\n",
    "train_rmse = rmse(prediction_traj[-1][train_inds], expt_means[train_inds])\n",
    "test_rmse = rmse(prediction_traj[-1][test_inds], expt_means[test_inds])\n",
    "print('initial parameters\\n\\ttrain RMSE = {:.3f}\\n\\ttest RMSE = {:.3f}'.format(train_rmse, test_rmse))\n",
    "\n",
    "def callback(x,i,g):\n",
    "    #if np.sum(np.isnan(x)) > 0:\n",
    "    #    raise(RuntimeError('NaNs encountered!'))\n",
    "    prediction_traj.append(make_predictions(x, inds=np.arange(len(mols))))\n",
    "    train_rmse = rmse(prediction_traj[-1][train_inds], expt_means[train_inds])\n",
    "    test_rmse = rmse(prediction_traj[-1][test_inds], expt_means[test_inds])\n",
    "    print('Iteration {}\\n\\ttrain RMSE = {:.3f}\\n\\ttest RMSE = {:.3f}'.format(i, train_rmse, test_rmse))\n",
    "    traj.append((x,i,g))\n",
    "result = adam(grad_loss, params, callback=callback, num_iters=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:32:35.230107Z",
     "start_time": "2019-03-07T15:32:35.193803Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savez('linear_typing_result_gaussian_loss.npz',\n",
    "         prediction_traj=prediction_traj,\n",
    "         train_inds=train_inds,\n",
    "         test_inds=test_inds,\n",
    "         expt_means=expt_means,\n",
    "         expt_uncs=expt_uncs,\n",
    "         traj=traj,\n",
    "         layer_sizes=layer_sizes,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:27:06.994214Z",
     "start_time": "2019-03-07T15:27:06.972944Z"
    }
   },
   "outputs": [],
   "source": [
    "train_rmses = [rmse(snapshot[train_inds], expt_means[train_inds]) for snapshot in prediction_traj]\n",
    "test_rmses = [rmse(snapshot[test_inds], expt_means[test_inds]) for snapshot in prediction_traj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:27:24.598916Z",
     "start_time": "2019-03-07T15:27:24.596096Z"
    }
   },
   "outputs": [],
   "source": [
    "train_color = 'lightblue'\n",
    "test_color = 'green'\n",
    "train_style = '--'\n",
    "test_style = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:27:25.140627Z",
     "start_time": "2019-03-07T15:27:24.961650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'adam iterations')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_rmses, c=train_color, linestyle=train_style)\n",
    "plt.plot(test_rmses, c=test_color, linestyle=test_style)\n",
    "plt.ylabel('RMSE (kcal/mol)')\n",
    "plt.xlabel('adam iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:33:20.630812Z",
     "start_time": "2019-03-07T15:33:20.624116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-23.060296548233325, 4.696338374455828)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minval, maxval = np.min(prediction_traj[50:]), np.max(prediction_traj[50:])\n",
    "minval, maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:34:53.275067Z",
     "start_time": "2019-03-07T15:34:53.271122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-15.5, 5.5)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minval, maxval = -15.5, 5.5\n",
    "minval, maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:34:53.388523Z",
     "start_time": "2019-03-07T15:34:53.384656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-14.21, 3.4300000000000006)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(expt_means), np.max(expt_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:34:53.838128Z",
     "start_time": "2019-03-07T15:34:53.835725Z"
    }
   },
   "outputs": [],
   "source": [
    "# color by group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:34:54.167357Z",
     "start_time": "2019-03-07T15:34:54.164504Z"
    }
   },
   "outputs": [],
   "source": [
    "train_color = 'lightblue'\n",
    "test_color = 'green'\n",
    "train_style = '--'\n",
    "test_style = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:34:54.315785Z",
     "start_time": "2019-03-07T15:34:54.309273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11433, 43)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.vstack(computed_features)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:34:54.529693Z",
     "start_time": "2019-03-07T15:34:54.523857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(inputs[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:34:56.111916Z",
     "start_time": "2019-03-07T15:34:56.109502Z"
    }
   },
   "outputs": [],
   "source": [
    "s = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:44:35.771044Z",
     "start_time": "2019-03-07T15:40:48.813072Z"
    }
   },
   "outputs": [],
   "source": [
    "from bayes_implicit_solvent.utils import remove_top_right_spines\n",
    "diag = np.arange(minval, maxval)\n",
    "\n",
    "for t in range(len(prediction_traj)):\n",
    "    plt.figure(figsize=(6*1.5,3*1.5))\n",
    "    ax = plt.subplot(1,2,1)\n",
    "    remove_top_right_spines(ax)\n",
    "    \n",
    "    plt.plot(train_rmses[:t], c=train_color, linestyle=train_style, label='train (n={})'.format(len(train_inds)))\n",
    "    plt.plot(test_rmses[:t], c=test_color, linestyle=test_style, label='test (n={})'.format(len(test_inds)))\n",
    "    plt.hlines(2.425900278028874, 0, len(train_rmses), linestyles='-', label='OBC2 (n=631)')\n",
    "    plt.hlines(1.642, 0, len(train_rmses), linestyles='--', label='SMIRNOFF+TIP3P (n=642)')\n",
    "    plt.hlines(0.98, 0, len(train_rmses), linestyles='dotted', label='OPLS3e (n=418)')\n",
    "    \n",
    "    \n",
    "    plt.ylabel('RMSE (kcal/mol)')\n",
    "    plt.xlabel('adam iterations')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.xlim(0, len(train_rmses))\n",
    "    plt.ylim(0, 4)\n",
    "    \n",
    "    plt.title('RMSE trace')\n",
    "    \n",
    "    ax = plt.subplot(1,2,2)\n",
    "    remove_top_right_spines(ax)\n",
    "    \n",
    "    plt.plot(diag, diag, linestyle='--', c='grey')\n",
    "    plt.scatter(prediction_traj[t][train_inds], expt_means[train_inds], c=train_color, alpha=0.8, s=s)\n",
    "    plt.scatter(prediction_traj[t][test_inds], expt_means[test_inds], c=test_color, alpha=0.8, s=s)\n",
    "    plt.xlim(minval, maxval)\n",
    "    plt.ylim(minval, maxval)\n",
    "    \n",
    "    plt.xticks([-15,-10,-5,0,5])\n",
    "    plt.yticks([-15,-10,-5,0,5])\n",
    "    \n",
    "    plt.xlabel(r'predicted $\\Delta G$ (kcal/mol)')\n",
    "    plt.ylabel(r'measured $\\Delta G$ (kcal/mol)')\n",
    "    \n",
    "    plt.title('train RMSE: {:.2f}\\ntest RMSE: {:.2f}'.format(train_rmses[t], test_rmses[t]))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('linear_parameterizer/{:04}.png'.format(t), bbox_inches='tight')\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
